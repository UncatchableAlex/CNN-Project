{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00080376],\n",
       "       [-0.00063198]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = np.array([\n",
    "    [0.1, 0.4],\n",
    "    [0.8, 0.6]\n",
    "])\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "activation = [sig, lambda x:  x*(1-x)]\n",
    "grad_output = np.array([[-0.00265], [-0.00817]])\n",
    "output = np.array([[0.35], [0.9]])\n",
    "activation[1](output) * (w @ grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0026569],\n",
       "       [-0.0081723]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([\n",
    "    [0.3],\n",
    "    [0.9]\n",
    "])\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "activation = [sig, lambda x:  x*(1-x)]\n",
    "grad_output = np.array([[-0.0407]])\n",
    "output = np.array([[0.680], [0.664]])\n",
    "activation[1](output) * (w @ grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m layer1 \u001b[38;5;241m=\u001b[39m \u001b[43mInput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m layer2 \u001b[38;5;241m=\u001b[39m Dense((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m, np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0.3\u001b[39m], [\u001b[38;5;241m0.9\u001b[39m]]))\n\u001b[0;32m      9\u001b[0m layer3 \u001b[38;5;241m=\u001b[39m Output((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m), np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0.5\u001b[39m]]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\alexm\\2024_Spring\\final_project\\model\\layers\\input.py:10\u001b[0m, in \u001b[0;36mInput.__init__\u001b[1;34m(self, input_shape, output_shape, w, activation)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# input\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape, output_shape, w, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# each column represents the weights leading into a node in the next layer\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# each row represents the weights from a node in the last layer\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m#self.w = np.random.uniform(-0.5, 0.5, (nodes, output_shape[0]))\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m=\u001b[39m w\n",
      "File \u001b[1;32mc:\\Users\\alexm\\2024_Spring\\final_project\\model\\layers\\layer.py:17\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, input_shape, output_shape, activation)\u001b[0m\n\u001b[0;32m     11\u001b[0m sig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mnp\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mx))\n\u001b[0;32m     12\u001b[0m activation_funcs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mmaximum(x, \u001b[38;5;241m0.0\u001b[39m), \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mwhere(x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)],\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m: [sig, \u001b[38;5;28;01mlambda\u001b[39;00m x:  sig(x)\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39msig(x))],\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     16\u001b[0m }\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m \u001b[43mactivation_funcs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "from model.layers.dense import Dense\n",
    "from model.layers.output import Output\n",
    "from model.layers.input import Input\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "layer1 = Input((2,0), (2,0), 2, np.array([[0.1,0.4], [0.8,0.6]]))\n",
    "layer2 = Dense((2,0), (1,0), 2, np.array([[0.3], [0.9]]))\n",
    "layer3 = Output((1,0), (1,0), np.array([[0.5]]), 'relu', '')\n",
    "\n",
    "input = np.array([[0.35,0.9]]).T\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "for i in range(100):\n",
    "    final_out = layer3.forward(layer2.forward(layer1.forward(input)))\n",
    "    print(final_out)\n",
    "    layer1.backward(layer2.backward(layer3.backward(final_out)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model that is only fully connected layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69028349]]\n",
      "[[0.68707769]]\n",
      "[[0.68387261]]\n",
      "[[0.68066925]]\n",
      "[[0.67746863]]\n",
      "[[0.67427179]]\n",
      "[[0.67107976]]\n",
      "[[0.66789361]]\n",
      "[[0.66471442]]\n",
      "[[0.66154325]]\n",
      "[[0.6583812]]\n",
      "[[0.65522936]]\n",
      "[[0.65208884]]\n",
      "[[0.64896074]]\n",
      "[[0.64584618]]\n",
      "[[0.64274627]]\n",
      "[[0.63966211]]\n",
      "[[0.63659482]]\n",
      "[[0.63354551]]\n",
      "[[0.63051527]]\n",
      "[[0.6275052]]\n",
      "[[0.62451639]]\n",
      "[[0.62154992]]\n",
      "[[0.61860686]]\n",
      "[[0.61568826]]\n",
      "[[0.61279516]]\n",
      "[[0.60992859]]\n",
      "[[0.60708957]]\n",
      "[[0.60427907]]\n",
      "[[0.60149808]]\n",
      "[[0.59874754]]\n",
      "[[0.59602838]]\n",
      "[[0.59334152]]\n",
      "[[0.59068781]]\n",
      "[[0.58806813]]\n",
      "[[0.58548329]]\n",
      "[[0.58293409]]\n",
      "[[0.58042129]]\n",
      "[[0.57794563]]\n",
      "[[0.57550781]]\n",
      "[[0.57310849]]\n",
      "[[0.57074831]]\n",
      "[[0.56842787]]\n",
      "[[0.56614771]]\n",
      "[[0.56390836]]\n",
      "[[0.56171031]]\n",
      "[[0.55955398]]\n",
      "[[0.5574398]]\n",
      "[[0.5553681]]\n",
      "[[0.55333922]]\n",
      "[[0.55135343]]\n",
      "[[0.54941097]]\n",
      "[[0.54751202]]\n",
      "[[0.54565673]]\n",
      "[[0.54384521]]\n",
      "[[0.54207752]]\n",
      "[[0.54035368]]\n",
      "[[0.53867367]]\n",
      "[[0.53703742]]\n",
      "[[0.53544482]]\n",
      "[[0.53389573]]\n",
      "[[0.53238996]]\n",
      "[[0.53092727]]\n",
      "[[0.5295074]]\n",
      "[[0.52813005]]\n",
      "[[0.52679487]]\n",
      "[[0.52550147]]\n",
      "[[0.52424946]]\n",
      "[[0.52303837]]\n",
      "[[0.52186773]]\n",
      "[[0.52073703]]\n",
      "[[0.51964572]]\n",
      "[[0.51859324]]\n",
      "[[0.51757899]]\n",
      "[[0.51660236]]\n",
      "[[0.51566269]]\n",
      "[[0.51475933]]\n",
      "[[0.51389158]]\n",
      "[[0.51305875]]\n",
      "[[0.51226011]]\n",
      "[[0.51149492]]\n",
      "[[0.51076245]]\n",
      "[[0.51006191]]\n",
      "[[0.50939255]]\n",
      "[[0.50875357]]\n",
      "[[0.5081442]]\n",
      "[[0.50756363]]\n",
      "[[0.50701108]]\n",
      "[[0.50648572]]\n",
      "[[0.50598677]]\n",
      "[[0.50551342]]\n",
      "[[0.50506487]]\n",
      "[[0.50464031]]\n",
      "[[0.50423896]]\n",
      "[[0.50386002]]\n",
      "[[0.5035027]]\n",
      "[[0.50316623]]\n",
      "[[0.50284984]]\n",
      "[[0.50255276]]\n",
      "[[0.50227425]]\n"
     ]
    }
   ],
   "source": [
    "from model.layers.dense import Dense\n",
    "from model.layers.output import Output\n",
    "from model.layers.input import Input\n",
    "from model.optimizers.adam import Adam\n",
    "import numpy as np\n",
    "\n",
    "adam = Adam()\n",
    "layer1 = Input((2,0), (2,0), 2, np.array([[0.1,0.4], [0.8,0.6]]))\n",
    "layer2 = Dense((2,0), (1,0), 2, np.array([[0.3], [0.9]]))\n",
    "layer2.compile(optimizer=adam)\n",
    "layer3 = Output((1,0), (1,0), np.array([[0.5]]), 'relu', '')\n",
    "\n",
    "input = np.array([[0.35,0.9]]).T\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "for i in range(100):\n",
    "    final_out = layer3.forward(layer2.forward(layer1.forward(input)))\n",
    "    print(final_out)\n",
    "    layer1.backward(layer2.backward(layer3.backward(final_out)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model that has convolutional layers and fully connected layers\n",
    "### but only do backprop on the fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from model.layers.conv2d import Conv2D\n",
    "from model.layers.output import Output\n",
    "from model.layers.input import Input\n",
    "from model.optimizers.adam import Adam\n",
    "from model.layers.flatten import Flatten\n",
    "from model.layers.dense import Dense\n",
    "import numpy as np\n",
    "\n",
    "adam = Adam()\n",
    "input = np.array([[\n",
    "    [1,2,3,4,5],\n",
    "    [6,7,8,9,10],\n",
    "    [11,12,13,14,15],\n",
    "    [16,17,18,19,20],\n",
    "    [21,22,23,24,25]\n",
    "],\n",
    "[\n",
    "    [30, 31, 32, 33, 34],\n",
    "    [35, 36, 37, 38, 39],\n",
    "    [40, 41, 42, 43, 44],\n",
    "    [45, 46, 47, 48, 49],\n",
    "    [50, 51, 52, 53, 54]]\n",
    "])\n",
    "\n",
    "\n",
    "convLayer = Conv2D(input_shape=(2,5,5), input.shape=(2,3,3), filters=2, kernel_size=3)\n",
    "flattenLayer = Flatten(input_shape=(2,3,3), input.shape=(18,1), activation='relu')\n",
    "flattenLayer.forward(convLayer.forward(input))\n",
    "\n",
    "layer2 = Dense(input_shape=(18,1), input.shape=(5,1))\n",
    "layer3 = Dense(input_shape=(5,1), input.shape=(1,1))\n",
    "\n",
    "layer2.compile(optimizer='adam')\n",
    "layer3.compile(optimizer='adam')\n",
    "output = Output((1,1), (1,1), np.array([[0.50]]), 'relu', '')\n",
    "\n",
    "for i in range(1000):\n",
    "     final_out = output.forward(layer3.forward(layer2.forward(flattenLayer.forward(convLayer.forward(input)))))\n",
    "     print(final_out)\n",
    "     # train fully-connected portion\n",
    "     #layer2.backward(layer3.backward(output.backward(final_out)))\n",
    "     \n",
    "     # train convolutional portion:\n",
    "     \n",
    "\n",
    "#layer3.forward(layer2.forward(flattenLayer.forward(convLayer.forward(input))))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train a network that has convolutional layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50261229]]\n",
      "[[0.5023452]]\n",
      "[[0.50207809]]\n",
      "[[0.5017912]]\n",
      "[[0.50154698]]\n",
      "[[0.50127819]]\n",
      "[[0.5010285]]\n",
      "[[0.50076478]]\n",
      "[[0.50051046]]\n",
      "[[0.50026073]]\n",
      "[[0.50000511]]\n",
      "[[0.49975446]]\n",
      "[[0.49950309]]\n",
      "[[0.4992524]]\n",
      "[[0.49900218]]\n",
      "[[0.49875242]]\n",
      "[[0.4985029]]\n",
      "[[0.49825344]]\n",
      "[[0.49800404]]\n",
      "[[0.4977547]]\n",
      "[[0.49750543]]\n",
      "[[0.49725623]]\n",
      "[[0.4970071]]\n",
      "[[0.49675804]]\n",
      "[[0.49650906]]\n",
      "[[0.49626016]]\n",
      "[[0.49601133]]\n",
      "[[0.49576259]]\n",
      "[[0.49551393]]\n",
      "[[0.49526536]]\n",
      "[[0.49501688]]\n",
      "[[0.49476848]]\n",
      "[[0.49452018]]\n",
      "[[0.49427196]]\n",
      "[[0.49402384]]\n",
      "[[0.49377582]]\n",
      "[[0.49352788]]\n",
      "[[0.49328005]]\n",
      "[[0.49303231]]\n",
      "[[0.49278467]]\n",
      "[[0.49253713]]\n",
      "[[0.49228968]]\n",
      "[[0.49204234]]\n",
      "[[0.4917951]]\n",
      "[[0.49154796]]\n",
      "[[0.49130093]]\n",
      "[[0.49105399]]\n",
      "[[0.49080716]]\n",
      "[[0.49056043]]\n",
      "[[0.49031381]]\n",
      "[[0.49006729]]\n",
      "[[0.48982088]]\n",
      "[[0.48957457]]\n",
      "[[0.48932836]]\n",
      "[[0.48908226]]\n",
      "[[0.48883627]]\n",
      "[[0.48859038]]\n",
      "[[0.4883446]]\n",
      "[[0.48809893]]\n",
      "[[0.48785336]]\n",
      "[[0.48760789]]\n",
      "[[0.48736253]]\n",
      "[[0.48711728]]\n",
      "[[0.48687214]]\n",
      "[[0.4866271]]\n",
      "[[0.48638217]]\n",
      "[[0.48613734]]\n",
      "[[0.48589262]]\n",
      "[[0.48564801]]\n",
      "[[0.4854035]]\n",
      "[[0.4851591]]\n",
      "[[0.4849148]]\n",
      "[[0.48467062]]\n",
      "[[0.48442653]]\n",
      "[[0.48418256]]\n",
      "[[0.48393868]]\n",
      "[[0.48369492]]\n",
      "[[0.48345126]]\n",
      "[[0.48320771]]\n",
      "[[0.48296426]]\n",
      "[[0.48272091]]\n",
      "[[0.48247768]]\n",
      "[[0.48223454]]\n",
      "[[0.48199152]]\n",
      "[[0.48174859]]\n",
      "[[0.48150578]]\n",
      "[[0.48126306]]\n",
      "[[0.48102045]]\n",
      "[[0.48077795]]\n",
      "[[0.48053555]]\n",
      "[[0.48029326]]\n",
      "[[0.48005106]]\n",
      "[[0.47980898]]\n",
      "[[0.47956699]]\n",
      "[[0.47932511]]\n",
      "[[0.47908334]]\n",
      "[[0.47884167]]\n",
      "[[0.4786001]]\n",
      "[[0.47835863]]\n",
      "[[0.47811727]]\n",
      "[[0.47787601]]\n",
      "[[0.47763485]]\n",
      "[[0.4773938]]\n",
      "[[0.47715284]]\n",
      "[[0.47691199]]\n",
      "[[0.47667125]]\n",
      "[[0.4764306]]\n",
      "[[0.47619006]]\n",
      "[[0.47594962]]\n",
      "[[0.47570928]]\n",
      "[[0.47546904]]\n",
      "[[0.4752289]]\n",
      "[[0.47498887]]\n",
      "[[0.47474894]]\n",
      "[[0.4745091]]\n",
      "[[0.47426937]]\n",
      "[[0.47402974]]\n",
      "[[0.47379021]]\n",
      "[[0.47355078]]\n",
      "[[0.47331145]]\n",
      "[[0.47307222]]\n",
      "[[0.47283309]]\n",
      "[[0.47259406]]\n",
      "[[0.47235513]]\n",
      "[[0.4721163]]\n",
      "[[0.47187757]]\n",
      "[[0.47163894]]\n",
      "[[0.47140041]]\n",
      "[[0.47116198]]\n",
      "[[0.47092365]]\n",
      "[[0.47068541]]\n",
      "[[0.47044728]]\n",
      "[[0.47020924]]\n",
      "[[0.4699713]]\n",
      "[[0.46973347]]\n",
      "[[0.46949572]]\n",
      "[[0.46925808]]\n",
      "[[0.46902054]]\n",
      "[[0.46878309]]\n",
      "[[0.46854574]]\n",
      "[[0.46830849]]\n",
      "[[0.46807133]]\n",
      "[[0.46783428]]\n",
      "[[0.46759732]]\n",
      "[[0.46736046]]\n",
      "[[0.46712369]]\n",
      "[[0.46688702]]\n",
      "[[0.46665045]]\n",
      "[[0.46641397]]\n",
      "[[0.4661776]]\n",
      "[[0.46594131]]\n",
      "[[0.46570513]]\n",
      "[[0.46546904]]\n",
      "[[0.46523304]]\n",
      "[[0.46499715]]\n",
      "[[0.46476134]]\n",
      "[[0.46452564]]\n",
      "[[0.46429003]]\n",
      "[[0.46405451]]\n",
      "[[0.46381909]]\n",
      "[[0.46358377]]\n",
      "[[0.46334853]]\n",
      "[[0.4631134]]\n",
      "[[0.46287836]]\n",
      "[[0.46264341]]\n",
      "[[0.46240856]]\n",
      "[[0.46217381]]\n",
      "[[0.46193914]]\n",
      "[[0.46170458]]\n",
      "[[0.4614701]]\n",
      "[[0.46123572]]\n",
      "[[0.46100143]]\n",
      "[[0.46076724]]\n",
      "[[0.46053314]]\n",
      "[[0.46029914]]\n",
      "[[0.46006523]]\n",
      "[[0.45983141]]\n",
      "[[0.45959768]]\n",
      "[[0.45936405]]\n",
      "[[0.45913051]]\n",
      "[[0.45889706]]\n",
      "[[0.45866371]]\n",
      "[[0.45843045]]\n",
      "[[0.45819728]]\n",
      "[[0.4579642]]\n",
      "[[0.45773122]]\n",
      "[[0.45749833]]\n",
      "[[0.45726553]]\n",
      "[[0.45703282]]\n",
      "[[0.45680021]]\n",
      "[[0.45656768]]\n",
      "[[0.45633525]]\n",
      "[[0.45610291]]\n",
      "[[0.45587066]]\n",
      "[[0.4556385]]\n",
      "[[0.45540643]]\n",
      "[[0.45517446]]\n",
      "[[0.45494258]]\n",
      "[[0.45471078]]\n",
      "[[0.45447908]]\n",
      "[[0.45424747]]\n",
      "[[0.45401595]]\n",
      "[[0.45378451]]\n",
      "[[0.45355317]]\n",
      "[[0.45332192]]\n",
      "[[0.45309077]]\n",
      "[[0.4528597]]\n",
      "[[0.45262872]]\n",
      "[[0.45239783]]\n",
      "[[0.45216703]]\n",
      "[[0.45193632]]\n",
      "[[0.4517057]]\n",
      "[[0.45147517]]\n",
      "[[0.45124473]]\n",
      "[[0.45101437]]\n",
      "[[0.45078411]]\n",
      "[[0.45055394]]\n",
      "[[0.45032385]]\n",
      "[[0.45009386]]\n",
      "[[0.44986395]]\n",
      "[[0.44963414]]\n",
      "[[0.44940441]]\n",
      "[[0.44917477]]\n",
      "[[0.44894522]]\n",
      "[[0.44871575]]\n",
      "[[0.44848638]]\n",
      "[[0.44825709]]\n",
      "[[0.44802789]]\n",
      "[[0.44779879]]\n",
      "[[0.44756976]]\n",
      "[[0.44734083]]\n",
      "[[0.44711198]]\n",
      "[[0.44688323]]\n",
      "[[0.44665456]]\n",
      "[[0.44642597]]\n",
      "[[0.44619748]]\n",
      "[[0.44596907]]\n",
      "[[0.44574075]]\n",
      "[[0.44551252]]\n",
      "[[0.44528437]]\n",
      "[[0.44505632]]\n",
      "[[0.44482834]]\n",
      "[[0.44460046]]\n",
      "[[0.44437266]]\n",
      "[[0.44414495]]\n",
      "[[0.44391733]]\n",
      "[[0.44368979]]\n",
      "[[0.44346234]]\n",
      "[[0.44323498]]\n",
      "[[0.4430077]]\n",
      "[[0.44278051]]\n",
      "[[0.44255341]]\n",
      "[[0.44232639]]\n",
      "[[0.44209946]]\n",
      "[[0.44187261]]\n",
      "[[0.44164585]]\n",
      "[[0.44141918]]\n",
      "[[0.44119259]]\n",
      "[[0.44096609]]\n",
      "[[0.44073967]]\n",
      "[[0.44051334]]\n",
      "[[0.4402871]]\n",
      "[[0.44006094]]\n",
      "[[0.43983487]]\n",
      "[[0.43960888]]\n",
      "[[0.43938298]]\n",
      "[[0.43915716]]\n",
      "[[0.43893143]]\n",
      "[[0.43870578]]\n",
      "[[0.43848022]]\n",
      "[[0.43825474]]\n",
      "[[0.43802935]]\n",
      "[[0.43780405]]\n",
      "[[0.43757882]]\n",
      "[[0.43735369]]\n",
      "[[0.43712864]]\n",
      "[[0.43690367]]\n",
      "[[0.43667879]]\n",
      "[[0.43645399]]\n",
      "[[0.43622928]]\n",
      "[[0.43600465]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from model.layers.conv2d import Conv2D\n",
    "from model.layers.output import Output\n",
    "from model.layers.flatten import Flatten\n",
    "from model.layers.dense import Dense\n",
    "from model.layers.maxpool2d import MaxPool2D\n",
    "from model.layers.dropout import ConvDropout, DenseDropout\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "input = np.random.uniform(low=-1, high=1, size=(2,12,12))\n",
    "# make convolutional layers\n",
    "convLayer1 = Conv2D(input_shape=(2,12,12), output_shape=(4,10,10), filters=4, kernel_size=3, activation='relu')\n",
    "convLayer1.compile(optimizer='adam')\n",
    "\n",
    "convDropoutLayer = ConvDropout(input_shape=(4,10,10), output_shape=(4,10,10), dropout_rate=0.5)\n",
    "\n",
    "convLayer2 = Conv2D(input_shape=(4,10,10), output_shape=(10,7,7), filters=10, kernel_size=4, activation='relu')\n",
    "convLayer2.compile(optimizer='adam')\n",
    "\n",
    "poolingLayer = MaxPool2D(input_shape=(10,7,7), output_shape=(10,3,3), pool_size=(5,5))\n",
    "\n",
    "convLayer3 = Conv2D(input_shape=(10,3,3), output_shape=(1,3,3), filters=1, kernel_size=1, activation='relu')\n",
    "convLayer3.compile(optimizer='adam')\n",
    "\n",
    "# make flatten layer\n",
    "flattenLayer = Flatten(input_shape=(1,3,3), output_shape=(9,1), activation='relu')\n",
    "\n",
    "# make fully connected layers\n",
    "layer2 = Dense(input_shape=(9,1), output_shape=(5,1), activation='relu')\n",
    "layer2.compile(optimizer='adam')\n",
    "\n",
    "denseDropoutLayer = DenseDropout(input_shape=(5,1), output_shape=(5,1), dropout_rate=0.5)\n",
    "\n",
    "layer3 = Dense(input_shape=(5,1), output_shape=(1,1), activation='relu')\n",
    "layer3.compile(optimizer='adam')\n",
    "\n",
    "# make output\n",
    "output = Output((1,1), (1,1), np.array([[0.24]]), 'sigmoid', '')\n",
    "\n",
    "iters = 2000\n",
    "for i in range(iters):\n",
    "     conv_out = convLayer3.forward(poolingLayer.forward(convLayer2.forward(convDropoutLayer.forward(convLayer1.forward(input)))))\n",
    "     final_out = output.forward(layer3.forward(denseDropoutLayer.forward(layer2.forward(flattenLayer.forward(conv_out)))))\n",
    "     print(final_out)\n",
    "     # train fully-connected portion\n",
    "     fully_connected_backprop = layer2.backward(denseDropoutLayer.backward(layer3.backward(output.backward(final_out))))\n",
    "     # train convolutional portion:\n",
    "     convLayer1.backward(convDropoutLayer.backward(convLayer2.backward(poolingLayer.backward(convLayer3.backward(flattenLayer.backward(fully_connected_backprop))))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiple channel example of maxpooling backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray([[\n\u001b[0;32m      2\u001b[0m     [\u001b[38;5;241m111\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m],\n\u001b[0;32m      3\u001b[0m     [\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      4\u001b[0m     [\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m13\u001b[39m,\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m15\u001b[39m],\n\u001b[0;32m      5\u001b[0m     [\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m17\u001b[39m,\u001b[38;5;241m18\u001b[39m,\u001b[38;5;241m19\u001b[39m,\u001b[38;5;241m20\u001b[39m],\n\u001b[0;32m      6\u001b[0m     [\u001b[38;5;241m21\u001b[39m,\u001b[38;5;241m22\u001b[39m,\u001b[38;5;241m23\u001b[39m,\u001b[38;5;241m24\u001b[39m,\u001b[38;5;241m25\u001b[39m]\n\u001b[0;32m      7\u001b[0m ],\n\u001b[0;32m      8\u001b[0m [\n\u001b[0;32m      9\u001b[0m     [\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m31\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m33\u001b[39m, \u001b[38;5;241m34\u001b[39m],\n\u001b[0;32m     10\u001b[0m     [\u001b[38;5;241m35\u001b[39m, \u001b[38;5;241m36\u001b[39m, \u001b[38;5;241m37\u001b[39m, \u001b[38;5;241m38\u001b[39m, \u001b[38;5;241m39\u001b[39m],\n\u001b[0;32m     11\u001b[0m     [\u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m41\u001b[39m, \u001b[38;5;241m42\u001b[39m, \u001b[38;5;241m43\u001b[39m, \u001b[38;5;241m44\u001b[39m],\n\u001b[0;32m     12\u001b[0m     [\u001b[38;5;241m45\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m44\u001b[39m, \u001b[38;5;241m488\u001b[39m, \u001b[38;5;241m49\u001b[39m],\n\u001b[0;32m     13\u001b[0m     [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m51\u001b[39m, \u001b[38;5;241m52\u001b[39m, \u001b[38;5;241m53\u001b[39m, \u001b[38;5;241m54\u001b[39m]]\n\u001b[0;32m     14\u001b[0m ])\n\u001b[0;32m     16\u001b[0m pool_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     17\u001b[0m stride \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "input = np.array([[\n",
    "    [111,2,3,4,5],\n",
    "    [6,7,8,9,10],\n",
    "    [11,12,13,14,15],\n",
    "    [16,17,18,19,20],\n",
    "    [21,22,23,24,25]\n",
    "],\n",
    "[\n",
    "    [30, 31, 32, 33, 34],\n",
    "    [35, 36, 37, 38, 39],\n",
    "    [40, 41, 42, 43, 44],\n",
    "    [45, 4, 44, 488, 49],\n",
    "    [50, 51, 52, 53, 54]]\n",
    "])\n",
    "\n",
    "pool_size = (3,3)\n",
    "stride = 1\n",
    "output_size = int((input.shape[1] - pool_size[0])/stride) + 1\n",
    "output = np.zeros((input.shape[0], output_size, output_size))\n",
    "positions = np.zeros(output.shape, dtype=(int, 3))\n",
    "for i in range(output_size): # rows\n",
    "    for j in range(output_size): # columns\n",
    "        row_start = i*stride\n",
    "        row_end = row_start + pool_size[0]\n",
    "        col_start = j*stride\n",
    "        col_end = col_start + pool_size[1]\n",
    "        for k in range(input.shape[0]): # channels\n",
    "            frame = input[k,row_start:row_end, col_start:col_end]\n",
    "            output[k,i,j] = np.max(frame)\n",
    "            # get the spot in the frame with the max value\n",
    "            positions[k,i,j,1:] = np.unravel_index(np.argmax(frame), frame.shape)\n",
    "            # add channel to position\n",
    "            positions[k,i,j,0] = k\n",
    "            # add offsets to get the spot in the output matrix with max value of this frame\n",
    "            positions[k,i,j,1] += row_start\n",
    "            positions[k,i,j,2] += col_start\n",
    "            \n",
    "output_grads = np.array(\n",
    "    [\n",
    "        [\n",
    "            [1, 2, 3],\n",
    "            [4,5,6],\n",
    "            [7,8,9]\n",
    "        ],\n",
    "\n",
    "        [\n",
    "            [10,11,12],\n",
    "            [13,14,15],\n",
    "            [16,17,18]\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "r_val = np.zeros(input.shape)\n",
    "channel_pos = positions[:, :, :, 0]\n",
    "row_pos = positions[:, :, :, 1]\n",
    "col_pos = positions[:, :, :, 2]\n",
    "r_val[channel_pos, row_pos, col_pos] = output_grads\n",
    "print(input)\n",
    "print(output)\n",
    "print(r_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple channel example of dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1]\n",
      " [1 1 0 3 1 4 1 1 0 0 4 4 0 2 1 4 0 0 0 1 2 1 0 0 4]\n",
      " [2 3 1 0 0 4 0 2 0 0 3 2 1 3 0 3 3 0 1 0 4 4 3 4 1]]\n",
      "[[[  0   0   3   0   0]\n",
      "  [  0   7   0   0  10]\n",
      "  [ 11  12  13   0  15]\n",
      "  [ 16  17  18  19  20]\n",
      "  [ 21  22  23  24   0]]\n",
      "\n",
      " [[  0   0  32   0  34]\n",
      "  [  0  36   0  38   0]\n",
      "  [ 40  41  42  43   0]\n",
      "  [  0   4  44 488  49]\n",
      "  [ 50   0   0   0  54]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   3,   0,   0],\n",
       "        [  0,   7,   0,   0,  10],\n",
       "        [ 11,  12,  13,   0,  15],\n",
       "        [ 16,  17,  18,  19,  20],\n",
       "        [ 21,  22,  23,  24,   0]],\n",
       "\n",
       "       [[  0,   0,  32,   0,  34],\n",
       "        [  0,  36,   0,  38,   0],\n",
       "        [ 40,  41,  42,  43,   0],\n",
       "        [  0,   4,  44, 488,  49],\n",
       "        [ 50,   0,   0,   0,  54]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = np.array([[\n",
    "    [111,2,3,4,5],\n",
    "    [6,7,8,9,10],\n",
    "    [11,12,13,14,15],\n",
    "    [16,17,18,19,20],\n",
    "    [21,22,23,24,25]\n",
    "],\n",
    "[\n",
    "    [30, 31, 32, 33, 34],\n",
    "    [35, 36, 37, 38, 39],\n",
    "    [40, 41, 42, 43, 44],\n",
    "    [45, 4, 44, 488, 49],\n",
    "    [50, 51, 52, 53, 54]]\n",
    "])\n",
    "input_shape = input.shape\n",
    "dropout_rate = 0.5\n",
    "\n",
    "dropout_num = int(input_shape[0] * input_shape[1] * input_shape[2] * dropout_rate)\n",
    "z_coord = np.random.randint(low=0, high=input.shape[0], size=dropout_num)\n",
    "x_coord = np.random.randint(low=0, high=input_shape[1], size=dropout_num)\n",
    "y_coord = np.random.randint(low=0, high=input_shape[2], size=dropout_num)\n",
    "positions = np.stack((z_coord, x_coord, y_coord))\n",
    "print(positions)\n",
    "input_copy = np.copy(input)\n",
    "input_copy[z_coord,x_coord,y_coord] = 0.0\n",
    "print(input_copy)\n",
    "\n",
    "\n",
    "output_grads = input\n",
    "# this is a matrix of the channel coordinates for each of the max values that we outputed upon forward prop\n",
    "channel_pos = positions[0]\n",
    "# and a matrix for the row coordinates\n",
    "row_pos = positions[1]\n",
    "# and a matrix for the col coordinates\n",
    "col_pos = positions[2]\n",
    "output_grads[channel_pos, row_pos, col_pos] = 0.0\n",
    "output_grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50264219]]\n",
      "[[0.50236369]]\n",
      "[[0.5020888]]\n",
      "[[0.50181744]]\n",
      "[[0.50154948]]\n",
      "[[0.50128472]]\n",
      "[[0.50102298]]\n",
      "[[0.50076403]]\n",
      "[[0.50050761]]\n",
      "[[0.50025344]]\n"
     ]
    }
   ],
   "source": [
    "from sequential import Sequential\n",
    "\n",
    "from model.layers.conv2d import Conv2D\n",
    "from model.layers.output import Output\n",
    "from model.layers.flatten import Flatten\n",
    "from model.layers.dense import Dense\n",
    "from model.layers.maxpool2d import MaxPool2D\n",
    "from model.layers.dropout import ConvDropout, DenseDropout\n",
    "import numpy as np\n",
    "\n",
    "path = '/Users/jiafeng/Library/CloudStorage/OneDrive-/cs431/final_cnn/sub_data'  #absolute path \n",
    "sequential = Sequential()\n",
    "train_value,train_target, validation_value , validation_target =sequential.preprocess_dataset(path,'c')\n",
    "\n",
    "#input = train_value[0]   #np.random.uniform(low=-1, high=1, size=(2,12,12))\n",
    "\n",
    "\n",
    "# make convolutional layers\n",
    "convLayer1 = Conv2D(input_shape=(2,12,12), output_shape=(4,10,10), filters=4, kernel_size=3, activation='relu')\n",
    "convDropoutLayer = ConvDropout(input_shape=(4,10,10), output_shape=(4,10,10), dropout_rate=0.5)\n",
    "convLayer2 = Conv2D(input_shape=(4,10,10), output_shape=(10,7,7), filters=10, kernel_size=4, activation='relu')\n",
    "poolingLayer = MaxPool2D(input_shape=(10,7,7), output_shape=(10,3,3), pool_size=(5,5))\n",
    "convLayer3 = Conv2D(input_shape=(10,3,3), output_shape=(1,3,3), filters=1, kernel_size=1, activation='relu')\n",
    "\n",
    "# make flatten layer\n",
    "flattenLayer = Flatten(input_shape=(1,3,3), output_shape=(9,1), activation='relu')\n",
    "layer2 = Dense(input_shape=(9,1), output_shape=(5,1), activation='relu')\n",
    "denseDropoutLayer = DenseDropout(input_shape=(5,1), output_shape=(5,1), dropout_rate=0.5)\n",
    "layer3 = Dense(input_shape=(5,1), output_shape=(1,1), activation='relu')\n",
    "# make output\n",
    "output = Output((1,1), (1,1), train_target[0], 'sigmoid')\n",
    "input = np.random.uniform(low=-1, high=1, size=(2,12,12))\n",
    "sequential = Sequential()\n",
    "\n",
    "\n",
    "sequential.add(convLayer1)\n",
    "sequential.add(convLayer2)\n",
    "sequential.add(poolingLayer)\n",
    "sequential.add(convLayer3)\n",
    "sequential.add(flattenLayer)\n",
    "sequential.add(layer2)\n",
    "sequential.add(layer3)\n",
    "sequential.add(output)\n",
    "\n",
    "sequential.compile('adam')\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    final_out =sequential.forward(input)\n",
    "    print(final_out)\n",
    "    sequential.backward(final_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "conv2d\n",
      "maxpool2d\n",
      "conv2d\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "output\n"
     ]
    }
   ],
   "source": [
    "for layer in sequential.layers:\n",
    "    print(str(type(layer)).split('.')[-1].lower()[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'alexbot3', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m sequential \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malexbot3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m sequential\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#input = np.random.uniform(low=-1, high=1, size=(2,12,12))\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/final_cnn/CNN-Project/sequential.py:129\u001b[0m, in \u001b[0;36mSequential.load\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(file_name):\n\u001b[0;32m--> 129\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     seq \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m    131\u001b[0m     layer_types \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(f\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer_types\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'alexbot3', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "from sequential import Sequential\n",
    "import numpy as np\n",
    "sequential = Sequential.load('alexbot3')\n",
    "sequential.compile('adam')\n",
    "#input = np.random.uniform(low=-1, high=1, size=(2,12,12))\n",
    "for i in range(150):\n",
    "    final_out =sequential.forward(input)\n",
    "    print(final_out)\n",
    "    sequential.backward(final_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential.save('alexbot3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "f = h5py.File('mydataset.hdf5', 'a')\n",
    "f.create_group('conv_layer')\n",
    "f['conv_layer'].create_dataset('weights', data=(1,2,3))\n",
    "f['conv_layer'].attrs['my_string'] = ['alex was here', 'and here too']\n",
    "f.create_group('randoms')\n",
    "f['randoms'].create_dataset('nums', data=np.random.uniform(low=-1, high=1, size=(3,3)))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alex was here' 'and here too']\n",
      "(1, 2, 3)\n",
      "[[-0.58416409  0.3960205  -0.77526037]\n",
      " [-0.53014562  0.14488003  0.78839453]\n",
      " [-0.07403817 -0.63193147  0.0884415 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "f = h5py.File('mydataset.hdf5', 'r')\n",
    "print(np.array(f['conv_layer'].attrs['my_string']))\n",
    "print(tuple(f['conv_layer']['weights']))\n",
    "print(np.array(f['randoms']['nums']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "[[0.01]]\n",
      "[[1.]]\n",
      "[[0.01]]\n"
     ]
    }
   ],
   "source": [
    "from sequential import Sequential\n",
    "\n",
    "from model.layers.conv2d import Conv2D\n",
    "from model.layers.output import Output\n",
    "from model.layers.flatten import Flatten\n",
    "from model.layers.dense import Dense\n",
    "from model.layers.maxpool2d import MaxPool2D\n",
    "from model.layers.dropout import ConvDropout, DenseDropout\n",
    "import numpy as np\n",
    "\n",
    "path = './sub_data'  #absolute path \n",
    "sequential = Sequential()\n",
    "train_value,train_target, validation_value , validation_target =sequential.preprocess_dataset(path,'c')\n",
    "\n",
    "input = train_value[0]   #np.random.uniform(low=-1, high=1, size=(2,12,12))\n",
    "# make convolutional layers\n",
    "\n",
    "convLayer1 = Conv2D(input_shape=(3,100,100), output_shape=(4,93,93), filters=4, kernel_size=8, activation='relu')\n",
    "convDropoutLayer = ConvDropout(input_shape=(4,93,93), output_shape=(4,93,93), dropout_rate=0.5)\n",
    "convLayer2 = Conv2D(input_shape=(4,93,93), output_shape=(10,78,78), filters=10, kernel_size=16, activation='relu')\n",
    "poolingLayer = MaxPool2D(input_shape=(10,78,78), output_shape=(10,59,59), pool_size=(20,20))\n",
    "convLayer3 = Conv2D(input_shape=(10,59,59), output_shape=(1,30,30), filters=1, kernel_size=30, activation='relu')\n",
    "\n",
    "#make flatten layer\n",
    "\n",
    "flattenLayer = Flatten(input_shape=(1,30,30), output_shape=(900,1), activation='relu')\n",
    "layer2 = Dense(input_shape=(900,1), output_shape=(900,1), activation='relu')\n",
    "denseDropoutLayer = DenseDropout(input_shape=(900,1), output_shape=(900,1), dropout_rate=0.5)\n",
    "layer3 = Dense(input_shape=(900,1), output_shape=(1,1), activation='relu')\n",
    "output = Output((1,1), (1,1), train_target[0], 'sigmoid')\n",
    "\n",
    "sequential.add(convLayer1)\n",
    "sequential.add(convLayer2)\n",
    "sequential.add(poolingLayer)\n",
    "sequential.add(convLayer3)\n",
    "sequential.add(flattenLayer)\n",
    "sequential.add(layer2)\n",
    "sequential.add(layer3)\n",
    "sequential.add(output)\n",
    "\n",
    "sequential.compile('adam')\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    final_out =sequential.forward(input)\n",
    "    print(final_out)\n",
    "    print(sequential.layers[-2].b)\n",
    "    sequential.backward(final_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test sub_data set(22 pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.00784314 0.00784314 0.00784314 ... 0.00784314 0.00784314 0.00784314]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]]\n",
      "[[1.]\n",
      " [1.]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 54\u001b[0m\n\u001b[1;32m     49\u001b[0m sequential\u001b[38;5;241m.\u001b[39madd(output)\n\u001b[1;32m     50\u001b[0m sequential\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m \u001b[43msequential\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnumber_of_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/cnn/CNN-Project/sequential.py:90\u001b[0m, in \u001b[0;36mSequential.training\u001b[0;34m(self, train_value, train_target, number_of_iteration)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m#change the final output\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39mtarget\n\u001b[0;32m---> 90\u001b[0m output \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(output\u001b[38;5;241m=\u001b[39moutput)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/cnn/CNN-Project/sequential.py:27\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input, index)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m     26\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[index]\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/cnn/CNN-Project/sequential.py:26\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input, index)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m---> 26\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(output, index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/cnn/CNN-Project/model/layers/conv2d.py:35\u001b[0m, in \u001b[0;36mConv2D.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# convolve each kernel with result of the activation function and the input\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,kern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernels):\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput[i] \u001b[38;5;241m=\u001b[39m \u001b[43mkern\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_convolve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_activ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/cnn/CNN-Project/kernel.py:27\u001b[0m, in \u001b[0;36mKernel.forward_convolve\u001b[0;34m(self, input_activ)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_convolve\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_activ):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mKernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_activ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/cnn/CNN-Project/kernel.py:63\u001b[0m, in \u001b[0;36mKernel._convolve\u001b[0;34m(input, weights, stride)\u001b[0m\n\u001b[1;32m     61\u001b[0m         col_start \u001b[38;5;241m=\u001b[39m j\u001b[38;5;241m*\u001b[39mstride\n\u001b[1;32m     62\u001b[0m         col_end \u001b[38;5;241m=\u001b[39m col_start \u001b[38;5;241m+\u001b[39m weights\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m---> 63\u001b[0m         output[i,j] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mrow_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcol_end\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/fromnumeric.py:2172\u001b[0m, in \u001b[0;36m_sum_dispatcher\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;124;03m    Clip (limit) the values in an array.\u001b[39;00m\n\u001b[1;32m   2104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2167\u001b[0m \n\u001b[1;32m   2168\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m, a_min, a_max, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 2172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2173\u001b[0m                     initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[1;32m   2177\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[1;32m   2178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2179\u001b[0m         initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sequential import Sequential\n",
    "\n",
    "from model.layers.conv2d import Conv2D\n",
    "from model.layers.output import Output\n",
    "from model.layers.flatten import Flatten\n",
    "from model.layers.dense import Dense\n",
    "from model.layers.maxpool2d import MaxPool2D\n",
    "from model.layers.dropout import ConvDropout, DenseDropout\n",
    "import numpy as np\n",
    "\n",
    "path = '/Users/jiafeng/Library/CloudStorage/OneDrive-/cs431/cnn/sub_data'  #absolute path \n",
    "sequential = Sequential()\n",
    "map_dictionary={\n",
    "    'c':[[1],[0]],\n",
    "    'd':[[0],[1]]\n",
    "}\n",
    "train_value,train_target, validation_value , validation_target =sequential.preprocess_dataset(path,map_dictionary)\n",
    "\n",
    "#print(train_target[0])\n",
    "print(train_value[0])\n",
    "\n",
    "\n",
    "input = train_value[0]   #np.random.uniform(low=-1, high=1, size=(2,12,12))\n",
    "# make convolutional layers\n",
    "\n",
    "convLayer1 = Conv2D(input_shape=(3,100,100), output_shape=(4,93,93), filters=4, kernel_size=8, activation='relu')\n",
    "convDropoutLayer = ConvDropout(input_shape=(4,93,93), output_shape=(4,93,93), dropout_rate=0.5)\n",
    "convLayer2 = Conv2D(input_shape=(4,93,93), output_shape=(10,78,78), filters=10, kernel_size=16, activation='relu')\n",
    "poolingLayer = MaxPool2D(input_shape=(10,78,78), output_shape=(10,59,59), pool_size=(20,20))\n",
    "convLayer3 = Conv2D(input_shape=(10,59,59), output_shape=(1,30,30), filters=1, kernel_size=30, activation='relu')\n",
    "\n",
    "#make flatten layer\n",
    "flattenLayer = Flatten(input_shape=(1,30,30), output_shape=(900,1), activation='relu')\n",
    "layer2 = Dense(input_shape=(900,1), output_shape=(100,1), activation='relu')\n",
    "denseDropoutLayer = DenseDropout(input_shape=(100,1), output_shape=(100,1), dropout_rate=0.5)\n",
    "layer3 = Dense(input_shape=(100,1), output_shape=(2,1), activation='relu')\n",
    "output = Output((2,1), (2,1), train_target[0], 'sigmoid')\n",
    "\n",
    "\n",
    "\n",
    "sequential = Sequential()\n",
    "sequential.add(convLayer1)\n",
    "sequential.add(convLayer2)\n",
    "sequential.add(poolingLayer)\n",
    "sequential.add(convLayer3)\n",
    "sequential.add(flattenLayer)\n",
    "sequential.add(layer2)\n",
    "sequential.add(layer3)\n",
    "sequential.add(output)\n",
    "sequential.compile('adam')\n",
    "\n",
    "\n",
    "\n",
    "sequential.training(train_value=train_value,train_target=train_target,number_of_iteration=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
