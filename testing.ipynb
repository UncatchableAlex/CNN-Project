{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00080376],\n",
       "       [-0.00063198]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = np.array([\n",
    "    [0.1, 0.4],\n",
    "    [0.8, 0.6]\n",
    "])\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "activation = [sig, lambda x:  x*(1-x)]\n",
    "grad_output = np.array([[-0.00265], [-0.00817]])\n",
    "output = np.array([[0.35], [0.9]])\n",
    "activation[1](output) * (w @ grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0026569],\n",
       "       [-0.0081723]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([\n",
    "    [0.3],\n",
    "    [0.9]\n",
    "])\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "activation = [sig, lambda x:  x*(1-x)]\n",
    "grad_output = np.array([[-0.0407]])\n",
    "output = np.array([[0.680], [0.664]])\n",
    "activation[1](output) * (w @ grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69028349]]\n",
      "[[0.68205434]]\n",
      "[[0.67401164]]\n",
      "[[0.66617304]]\n",
      "[[0.65855334]]\n",
      "[[0.65116451]]\n",
      "[[0.64401584]]\n",
      "[[0.63711406]]\n",
      "[[0.63046358]]\n",
      "[[0.62406667]]\n",
      "[[0.6179237]]\n",
      "[[0.61203339]]\n",
      "[[0.60639301]]\n",
      "[[0.60099861]]\n",
      "[[0.59584523]]\n",
      "[[0.59092708]]\n",
      "[[0.58623767]]\n",
      "[[0.58177006]]\n",
      "[[0.57751687]]\n",
      "[[0.57347051]]\n",
      "[[0.56962319]]\n",
      "[[0.56596707]]\n",
      "[[0.5624943]]\n",
      "[[0.55919708]]\n",
      "[[0.55606772]]\n",
      "[[0.55309866]]\n",
      "[[0.55028256]]\n",
      "[[0.54761223]]\n",
      "[[0.54508073]]\n",
      "[[0.54268134]]\n",
      "[[0.5404076]]\n",
      "[[0.53825328]]\n",
      "[[0.5362124]]\n",
      "[[0.53427923]]\n",
      "[[0.53244831]]\n",
      "[[0.53071439]]\n",
      "[[0.52907247]]\n",
      "[[0.52751781]]\n",
      "[[0.52604585]]\n",
      "[[0.52465228]]\n",
      "[[0.523333]]\n",
      "[[0.5220841]]\n",
      "[[0.52090187]]\n",
      "[[0.51978279]]\n",
      "[[0.51872352]]\n",
      "[[0.51772088]]\n",
      "[[0.51677188]]\n",
      "[[0.51587365]]\n",
      "[[0.51502349]]\n",
      "[[0.51421884]]\n",
      "[[0.51345728]]\n",
      "[[0.5127365]]\n",
      "[[0.51205432]]\n",
      "[[0.51140869]]\n",
      "[[0.51079764]]\n",
      "[[0.51021932]]\n",
      "[[0.50967199]]\n",
      "[[0.50915398]]\n",
      "[[0.50866372]]\n",
      "[[0.50819974]]\n",
      "[[0.50776061]]\n",
      "[[0.50734501]]\n",
      "[[0.50695167]]\n",
      "[[0.50657941]]\n",
      "[[0.5062271]]\n",
      "[[0.50589365]]\n",
      "[[0.50557808]]\n",
      "[[0.5052794]]\n",
      "[[0.50499673]]\n",
      "[[0.5047292]]\n",
      "[[0.504476]]\n",
      "[[0.50423636]]\n",
      "[[0.50400956]]\n",
      "[[0.5037949]]\n",
      "[[0.50359174]]\n",
      "[[0.50339946]]\n",
      "[[0.50321748]]\n",
      "[[0.50304525]]\n",
      "[[0.50288223]]\n",
      "[[0.50272795]]\n",
      "[[0.50258193]]\n",
      "[[0.50244372]]\n",
      "[[0.50231292]]\n",
      "[[0.50218912]]\n",
      "[[0.50207195]]\n",
      "[[0.50196105]]\n",
      "[[0.50185609]]\n",
      "[[0.50175675]]\n",
      "[[0.50166272]]\n",
      "[[0.50157373]]\n",
      "[[0.5014895]]\n",
      "[[0.50140979]]\n",
      "[[0.50133434]]\n",
      "[[0.50126292]]\n",
      "[[0.50119534]]\n",
      "[[0.50113136]]\n",
      "[[0.50107082]]\n",
      "[[0.50101351]]\n",
      "[[0.50095927]]\n",
      "[[0.50090793]]\n"
     ]
    }
   ],
   "source": [
    "from model.layers.dense import Dense\n",
    "from model.layers.output import Output\n",
    "from model.layers.input import Input\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "layer1 = Input((2,0), (2,0), 2, np.array([[0.1,0.4], [0.8,0.6]]))\n",
    "layer2 = Dense((2,0), (1,0), 2, np.array([[0.3], [0.9]]))\n",
    "layer3 = Output((1,0), (1,0), np.array([[0.5]]), 'sigmoid', '')\n",
    "\n",
    "input = np.array([[0.35,0.9]]).T\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "for i in range(100):\n",
    "    final_out = layer3.forward(layer2.forward(layer1.forward(input)))\n",
    "    print(final_out)\n",
    "    layer1.backward(layer2.backward(layer3.backward(final_out)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model that is only fully connected layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69028349]]\n",
      "[[0.68707769]]\n",
      "[[0.68387261]]\n",
      "[[0.68066925]]\n",
      "[[0.67746863]]\n",
      "[[0.67427179]]\n",
      "[[0.67107976]]\n",
      "[[0.66789361]]\n",
      "[[0.66471442]]\n",
      "[[0.66154325]]\n",
      "[[0.6583812]]\n",
      "[[0.65522936]]\n",
      "[[0.65208884]]\n",
      "[[0.64896074]]\n",
      "[[0.64584618]]\n",
      "[[0.64274627]]\n",
      "[[0.63966211]]\n",
      "[[0.63659482]]\n",
      "[[0.63354551]]\n",
      "[[0.63051527]]\n",
      "[[0.6275052]]\n",
      "[[0.62451639]]\n",
      "[[0.62154992]]\n",
      "[[0.61860686]]\n",
      "[[0.61568826]]\n",
      "[[0.61279516]]\n",
      "[[0.60992859]]\n",
      "[[0.60708957]]\n",
      "[[0.60427907]]\n",
      "[[0.60149808]]\n",
      "[[0.59874754]]\n",
      "[[0.59602838]]\n",
      "[[0.59334152]]\n",
      "[[0.59068781]]\n",
      "[[0.58806813]]\n",
      "[[0.58548329]]\n",
      "[[0.58293409]]\n",
      "[[0.58042129]]\n",
      "[[0.57794563]]\n",
      "[[0.57550781]]\n",
      "[[0.57310849]]\n",
      "[[0.57074831]]\n",
      "[[0.56842787]]\n",
      "[[0.56614771]]\n",
      "[[0.56390836]]\n",
      "[[0.56171031]]\n",
      "[[0.55955398]]\n",
      "[[0.5574398]]\n",
      "[[0.5553681]]\n",
      "[[0.55333922]]\n",
      "[[0.55135343]]\n",
      "[[0.54941097]]\n",
      "[[0.54751202]]\n",
      "[[0.54565673]]\n",
      "[[0.54384521]]\n",
      "[[0.54207752]]\n",
      "[[0.54035368]]\n",
      "[[0.53867367]]\n",
      "[[0.53703742]]\n",
      "[[0.53544482]]\n",
      "[[0.53389573]]\n",
      "[[0.53238996]]\n",
      "[[0.53092727]]\n",
      "[[0.5295074]]\n",
      "[[0.52813005]]\n",
      "[[0.52679487]]\n",
      "[[0.52550147]]\n",
      "[[0.52424946]]\n",
      "[[0.52303837]]\n",
      "[[0.52186773]]\n",
      "[[0.52073703]]\n",
      "[[0.51964572]]\n",
      "[[0.51859324]]\n",
      "[[0.51757899]]\n",
      "[[0.51660236]]\n",
      "[[0.51566269]]\n",
      "[[0.51475933]]\n",
      "[[0.51389158]]\n",
      "[[0.51305875]]\n",
      "[[0.51226011]]\n",
      "[[0.51149492]]\n",
      "[[0.51076245]]\n",
      "[[0.51006191]]\n",
      "[[0.50939255]]\n",
      "[[0.50875357]]\n",
      "[[0.5081442]]\n",
      "[[0.50756363]]\n",
      "[[0.50701108]]\n",
      "[[0.50648572]]\n",
      "[[0.50598677]]\n",
      "[[0.50551342]]\n",
      "[[0.50506487]]\n",
      "[[0.50464031]]\n",
      "[[0.50423896]]\n",
      "[[0.50386002]]\n",
      "[[0.5035027]]\n",
      "[[0.50316623]]\n",
      "[[0.50284984]]\n",
      "[[0.50255276]]\n",
      "[[0.50227425]]\n"
     ]
    }
   ],
   "source": [
    "from model.layers.dense import Dense\n",
    "from model.layers.output import Output\n",
    "from model.layers.input import Input\n",
    "from model.optimizers.adam import Adam\n",
    "import numpy as np\n",
    "\n",
    "adam = Adam()\n",
    "layer1 = Input((2,0), (2,0), 2, np.array([[0.1,0.4], [0.8,0.6]]))\n",
    "layer2 = Dense((2,0), (1,0), 2, np.array([[0.3], [0.9]]))\n",
    "layer2.compile(optimizer=adam)\n",
    "layer3 = Output((1,0), (1,0), np.array([[0.5]]), 'sigmoid', '')\n",
    "\n",
    "input = np.array([[0.35,0.9]]).T\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "for i in range(100):\n",
    "    final_out = layer3.forward(layer2.forward(layer1.forward(input)))\n",
    "    print(final_out)\n",
    "    layer1.backward(layer2.backward(layer3.backward(final_out)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model that has convolutional layers and fully connected layers\n",
    "### but only do backprop on the fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.48752923]]\n",
      "[[0.50838565]]\n",
      "[[0.51145843]]\n",
      "[[0.50553661]]\n",
      "[[0.49750846]]\n",
      "[[0.49217312]]\n",
      "[[0.49190388]]\n",
      "[[0.49542026]]\n",
      "[[0.50044006]]\n",
      "[[0.50466917]]\n",
      "[[0.50643811]]\n",
      "[[0.50544781]]\n",
      "[[0.50249626]]\n",
      "[[0.49888727]]\n",
      "[[0.49605496]]\n",
      "[[0.49504302]]\n",
      "[[0.49603257]]\n",
      "[[0.49841507]]\n",
      "[[0.50116175]]\n",
      "[[0.50320483]]\n",
      "[[0.50383735]]\n",
      "[[0.50296442]]\n",
      "[[0.50105254]]\n",
      "[[0.4989068]]\n",
      "[[0.49737834]]\n",
      "[[0.49702397]]\n",
      "[[0.4978805]]\n",
      "[[0.49949923]]\n",
      "[[0.50116949]]\n",
      "[[0.50221452]]\n",
      "[[0.50226465]]\n",
      "[[0.50138455]]\n",
      "[[0.50001]]\n",
      "[[0.49875248]]\n",
      "[[0.49813883]]\n",
      "[[0.49838192]]\n",
      "[[0.4993044]]\n",
      "[[0.50044657]]\n",
      "[[0.50128748]]\n",
      "[[0.5014793]]\n",
      "[[0.50099033]]\n",
      "[[0.50009618]]\n",
      "[[0.49923778]]\n",
      "[[0.49881127]]\n",
      "[[0.49898223]]\n",
      "[[0.49961986]]\n",
      "[[0.50038054]]\n",
      "[[0.50088804]]\n",
      "[[0.50091767]]\n",
      "[[0.5004948]]\n",
      "[[0.49986523]]\n",
      "[[0.49936033]]\n",
      "[[0.49922529]]\n",
      "[[0.4994982]]\n",
      "[[0.50000411]]\n",
      "[[0.50046108]]\n",
      "[[0.50063484]]\n",
      "[[0.50045814]]\n",
      "[[0.50005416]]\n",
      "[[0.49965823]]\n",
      "[[0.49948391]]\n",
      "[[0.49960762]]\n",
      "[[0.49993575]]\n",
      "[[0.50026892]]\n",
      "[[0.50042094]]\n",
      "[[0.50032209]]\n",
      "[[0.50004984]]\n",
      "[[0.49977436]]\n",
      "[[0.49965453]]\n",
      "[[0.49974649]]\n",
      "[[0.49997806]]\n",
      "[[0.50020084]]\n",
      "[[0.50028374]]\n",
      "[[0.5001896]]\n",
      "[[0.49999033]]\n",
      "[[0.49981556]]\n",
      "[[0.49976963]]\n",
      "[[0.49986944]]\n",
      "[[0.5000405]]\n",
      "[[0.50017027]]\n",
      "[[0.50018131]]\n",
      "[[0.50007719]]\n",
      "[[0.49993395]]\n",
      "[[0.49984634]]\n",
      "[[0.49986564]]\n",
      "[[0.49996989]]\n",
      "[[0.50008383]]\n",
      "[[0.50013222]]\n",
      "[[0.50008913]]\n",
      "[[0.4999912]]\n",
      "[[0.49990838]]\n",
      "[[0.49989472]]\n",
      "[[0.4999532]]\n",
      "[[0.50003779]]\n",
      "[[0.50008863]]\n",
      "[[0.50007402]]\n",
      "[[0.50000988]]\n",
      "[[0.49994501]]\n",
      "[[0.49992454]]\n",
      "[[0.49995879]]\n",
      "[[0.50001874]]\n",
      "[[0.50005973]]\n",
      "[[0.50005441]]\n",
      "[[0.50001076]]\n",
      "[[0.49996356]]\n",
      "[[0.49994714]]\n",
      "[[0.49997059]]\n",
      "[[0.50001322]]\n",
      "[[0.5000421]]\n",
      "[[0.50003726]]\n",
      "[[0.50000535]]\n",
      "[[0.49997252]]\n",
      "[[0.49996333]]\n",
      "[[0.49998251]]\n",
      "[[0.50001302]]\n",
      "[[0.50003075]]\n",
      "[[0.50002342]]\n",
      "[[0.49999891]]\n",
      "[[0.49997759]]\n",
      "[[0.49997557]]\n",
      "[[0.49999265]]\n",
      "[[0.5000138]]\n",
      "[[0.50002215]]\n",
      "[[0.50001233]]\n",
      "[[0.49999375]]\n",
      "[[0.4999819]]\n",
      "[[0.49998556]]\n",
      "[[0.50000038]]\n",
      "[[0.50001347]]\n",
      "[[0.50001447]]\n",
      "[[0.50000369]]\n",
      "[[0.49999096]]\n",
      "[[0.49998681]]\n",
      "[[0.49999384]]\n",
      "[[0.50000525]]\n",
      "[[0.50001123]]\n",
      "[[0.50000735]]\n",
      "[[0.49999774]]\n",
      "[[0.49999094]]\n",
      "[[0.49999238]]\n",
      "[[0.50000008]]\n",
      "[[0.50000697]]\n",
      "[[0.50000729]]\n",
      "[[0.50000139]]\n",
      "[[0.49999487]]\n",
      "[[0.49999337]]\n",
      "[[0.49999771]]\n",
      "[[0.50000361]]\n",
      "[[0.50000581]]\n",
      "[[0.50000275]]\n",
      "[[0.49999759]]\n",
      "[[0.49999504]]\n",
      "[[0.49999709]]\n",
      "[[0.5000015]]\n",
      "[[0.50000416]]\n",
      "[[0.50000287]]\n",
      "[[0.49999915]]\n",
      "[[0.49999655]]\n",
      "[[0.49999729]]\n",
      "[[0.5000004]]\n",
      "[[0.50000285]]\n",
      "[[0.50000248]]\n",
      "[[0.49999989]]\n",
      "[[0.49999766]]\n",
      "[[0.49999778]]\n",
      "[[0.49999993]]\n",
      "[[0.50000193]]\n",
      "[[0.50000196]]\n",
      "[[0.50000016]]\n",
      "[[0.49999839]]\n",
      "[[0.49999829]]\n",
      "[[0.4999998]]\n",
      "[[0.50000135]]\n",
      "[[0.50000148]]\n",
      "[[0.5000002]]\n",
      "[[0.49999886]]\n",
      "[[0.49999873]]\n",
      "[[0.49999983]]\n",
      "[[0.50000098]]\n",
      "[[0.50000108]]\n",
      "[[0.50000013]]\n",
      "[[0.49999914]]\n",
      "[[0.49999908]]\n",
      "[[0.49999992]]\n",
      "[[0.50000075]]\n",
      "[[0.50000077]]\n",
      "[[0.50000003]]\n",
      "[[0.49999934]]\n",
      "[[0.49999936]]\n",
      "[[0.50000002]]\n",
      "[[0.50000059]]\n",
      "[[0.50000052]]\n",
      "[[0.49999994]]\n",
      "[[0.49999947]]\n",
      "[[0.49999958]]\n",
      "[[0.5000001]]\n",
      "[[0.50000047]]\n",
      "[[0.50000033]]\n",
      "[[0.49999987]]\n",
      "[[0.49999959]]\n",
      "[[0.49999976]]\n",
      "[[0.50000016]]\n",
      "[[0.50000036]]\n",
      "[[0.50000017]]\n",
      "[[0.49999983]]\n",
      "[[0.49999969]]\n",
      "[[0.49999989]]\n",
      "[[0.50000018]]\n",
      "[[0.50000025]]\n",
      "[[0.50000005]]\n",
      "[[0.49999982]]\n",
      "[[0.49999979]]\n",
      "[[0.49999999]]\n",
      "[[0.50000018]]\n",
      "[[0.50000016]]\n",
      "[[0.49999997]]\n",
      "[[0.49999983]]\n",
      "[[0.49999989]]\n",
      "[[0.50000005]]\n",
      "[[0.50000015]]\n",
      "[[0.50000007]]\n",
      "[[0.49999993]]\n",
      "[[0.49999987]]\n",
      "[[0.49999996]]\n",
      "[[0.50000008]]\n",
      "[[0.5000001]]\n",
      "[[0.50000001]]\n",
      "[[0.49999991]]\n",
      "[[0.49999992]]\n",
      "[[0.50000002]]\n",
      "[[0.50000008]]\n",
      "[[0.50000005]]\n",
      "[[0.49999997]]\n",
      "[[0.49999993]]\n",
      "[[0.49999997]]\n",
      "[[0.50000004]]\n",
      "[[0.50000006]]\n",
      "[[0.50000001]]\n",
      "[[0.49999995]]\n",
      "[[0.49999996]]\n",
      "[[0.50000001]]\n",
      "[[0.50000005]]\n",
      "[[0.50000003]]\n",
      "[[0.49999998]]\n",
      "[[0.49999996]]\n",
      "[[0.49999999]]\n",
      "[[0.50000003]]\n",
      "[[0.50000003]]\n",
      "[[0.5]]\n",
      "[[0.49999997]]\n",
      "[[0.49999998]]\n",
      "[[0.50000001]]\n",
      "[[0.50000003]]\n",
      "[[0.50000001]]\n",
      "[[0.49999998]]\n",
      "[[0.49999998]]\n",
      "[[0.5]]\n",
      "[[0.50000002]]\n",
      "[[0.50000001]]\n",
      "[[0.49999999]]\n",
      "[[0.49999998]]\n",
      "[[0.49999999]]\n",
      "[[0.50000001]]\n",
      "[[0.50000001]]\n",
      "[[0.5]]\n",
      "[[0.49999999]]\n",
      "[[0.49999999]]\n",
      "[[0.50000001]]\n",
      "[[0.50000001]]\n",
      "[[0.5]]\n",
      "[[0.49999999]]\n",
      "[[0.49999999]]\n",
      "[[0.5]]\n",
      "[[0.50000001]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.49999999]]\n",
      "[[0.5]]\n",
      "[[0.50000001]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.49999999]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from model.layers.conv2d import Conv2D\n",
    "from model.layers.output import Output\n",
    "from model.layers.input import Input\n",
    "from model.optimizers.adam import Adam\n",
    "from model.layers.flatten import Flatten\n",
    "from model.layers.dense import Dense\n",
    "import numpy as np\n",
    "\n",
    "adam = Adam()\n",
    "input = np.array([[\n",
    "    [1,2,3,4,5],\n",
    "    [6,7,8,9,10],\n",
    "    [11,12,13,14,15],\n",
    "    [16,17,18,19,20],\n",
    "    [21,22,23,24,25]\n",
    "],\n",
    "[\n",
    "    [30, 31, 32, 33, 34],\n",
    "    [35, 36, 37, 38, 39],\n",
    "    [40, 41, 42, 43, 44],\n",
    "    [45, 46, 47, 48, 49],\n",
    "    [50, 51, 52, 53, 54]]\n",
    "])\n",
    "\n",
    "\n",
    "convLayer = Conv2D(input_shape=(2,5,5), output_shape=(2,3,3), filters=2, kernel_size=3)\n",
    "flattenLayer = Flatten(input_shape=(2,3,3), output_shape=(18,1), activation='sigmoid')\n",
    "flattenLayer.forward(convLayer.forward(input))\n",
    "\n",
    "layer2 = Dense(input_shape=(18,1), output_shape=(5,1))\n",
    "layer3 = Dense(input_shape=(5,1), output_shape=(1,1))\n",
    "\n",
    "layer2.compile(optimizer='adam')\n",
    "layer3.compile(optimizer='adam')\n",
    "output = Output((1,1), (1,1), np.array([[0.50]]), 'sigmoid', '')\n",
    "\n",
    "for i in range(1000):\n",
    "     final_out = output.forward(layer3.forward(layer2.forward(flattenLayer.forward(convLayer.forward(input)))))\n",
    "     print(final_out)\n",
    "     # train fully-connected portion\n",
    "     #layer2.backward(layer3.backward(output.backward(final_out)))\n",
    "     \n",
    "     # train convolutional portion:\n",
    "     \n",
    "\n",
    "#layer3.forward(layer2.forward(flattenLayer.forward(convLayer.forward(input))))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train a network that is only convolutional layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.74807928]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n",
      "[[0.72568399]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from model.layers.conv2d import Conv2D\n",
    "from model.layers.output import Output\n",
    "from model.layers.input import Input\n",
    "from model.optimizers.adam import Adam\n",
    "from model.layers.flatten import Flatten\n",
    "from model.layers.dense import Dense\n",
    "import numpy as np\n",
    "\n",
    "adam = Adam()\n",
    "input = np.random.uniform(low=-1, high=1, size=(2,12,12))\n",
    "\n",
    "convLayer1 = Conv2D(input_shape=(2,12,12), output_shape=(2,10,10), filters=4, kernel_size=3)\n",
    "convLayer1.compile(optimizer='adam')\n",
    "convLayer2 = Conv2D(input_shape=(4,10,10), output_shape=(10,7,7), filters=10, kernel_size=4)\n",
    "convLayer2.compile(optimizer='adam')\n",
    "convLayer3 = Conv2D(input_shape=(10,7,7), output_shape=(1,3,3), filters=1, kernel_size=5)\n",
    "convLayer3.compile(optimizer='adam')\n",
    "\n",
    "flattenLayer = Flatten(input_shape=(1,3,3), output_shape=(9,1), activation='sigmoid')\n",
    "flattenLayer.forward(convLayer1.forward(input))\n",
    "\n",
    "layer2 = Dense(input_shape=(9,1), output_shape=(5,1))\n",
    "layer3 = Dense(input_shape=(5,1), output_shape=(1,1))\n",
    "\n",
    "layer2.compile(optimizer='adam')\n",
    "layer3.compile(optimizer='adam')\n",
    "output = Output((1,1), (1,1), np.array([[0.50]]), 'sigmoid', '')\n",
    "\n",
    "for i in range(50):\n",
    "     conv_out = convLayer3.forward(convLayer2.forward(convLayer1.forward(input)))\n",
    "     final_out = output.forward(layer3.forward(layer2.forward(flattenLayer.forward(conv_out))))\n",
    "     print(final_out)\n",
    "     # train fully-connected portion\n",
    "     fully_connected_backprop = layer2.backward(layer3.backward(output.backward(final_out)))\n",
    "     # train convolutional portion:\n",
    "     convLayer1.backward(convLayer2.backward(convLayer3.backward(flattenLayer.backward(fully_connected_backprop))))\n",
    "     \n",
    "\n",
    "#layer3.forward(layer2.forward(flattenLayer.forward(convLayer.forward(input))))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
