{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00080376],\n",
       "       [-0.00063198]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = np.array([\n",
    "    [0.1, 0.4],\n",
    "    [0.8, 0.6]\n",
    "])\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "activation = [sig, lambda x:  x*(1-x)]\n",
    "grad_output = np.array([[-0.00265], [-0.00817]])\n",
    "output = np.array([[0.35], [0.9]])\n",
    "activation[1](output) * (w @ grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0026569],\n",
       "       [-0.0081723]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([\n",
    "    [0.3],\n",
    "    [0.9]\n",
    "])\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "activation = [sig, lambda x:  x*(1-x)]\n",
    "grad_output = np.array([[-0.0407]])\n",
    "output = np.array([[0.680], [0.664]])\n",
    "activation[1](output) * (w @ grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m layer1 \u001b[38;5;241m=\u001b[39m Input((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m, np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0.1\u001b[39m,\u001b[38;5;241m0.4\u001b[39m], [\u001b[38;5;241m0.8\u001b[39m,\u001b[38;5;241m0.6\u001b[39m]]))\n\u001b[1;32m----> 8\u001b[0m layer2 \u001b[38;5;241m=\u001b[39m \u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m layer3 \u001b[38;5;241m=\u001b[39m Output((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m), np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0.5\u001b[39m]]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0.35\u001b[39m,\u001b[38;5;241m0.9\u001b[39m]])\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\alexm\\2024_Spring\\final_project\\model\\layers\\dense.py:12\u001b[0m, in \u001b[0;36mDense.__init__\u001b[1;34m(self, input_shape, output_shape, activation, bias)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# input\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape, output_shape, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m):\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# each column represents the weights leading into a node in the next layer\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# each row represents the weights from a node in the last layer\u001b[39;00m\n\u001b[0;32m     15\u001b[0m   \u001b[38;5;66;03m#  self.w = np.random.uniform(-1, 1, (input_shape[0], output_shape[0]))\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull((input_shape[\u001b[38;5;241m0\u001b[39m], output_shape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;241m1e-4\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\alexm\\2024_Spring\\final_project\\model\\layers\\layer.py:17\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, input_shape, output_shape, activation)\u001b[0m\n\u001b[0;32m     11\u001b[0m sig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mnp\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mx))\n\u001b[0;32m     12\u001b[0m activation_funcs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mmaximum(x, \u001b[38;5;241m0.0\u001b[39m), \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mwhere(x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)],\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m: [sig, \u001b[38;5;28;01mlambda\u001b[39;00m x:  sig(x)\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39msig(x))],\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     16\u001b[0m }\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m \u001b[43mactivation_funcs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "from model.layers.dense import Dense\n",
    "from model.layers.output import Output\n",
    "from model.layers.input import Input\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "layer1 = Input((2,0), (2,0), 2, np.array([[0.1,0.4], [0.8,0.6]]))\n",
    "layer2 = Dense((2,0), (1,0), 2, np.array([[0.3], [0.9]]))\n",
    "layer3 = Output((1,0), (1,0), np.array([[0.5]]), 'relu', '')\n",
    "\n",
    "input = np.array([[0.35,0.9]]).T\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "for i in range(100):\n",
    "    final_out = layer3.forward(layer2.forward(layer1.forward(input)))\n",
    "    print(final_out)\n",
    "    layer1.backward(layer2.backward(layer3.backward(final_out)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model that is only fully connected layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69028349]]\n",
      "[[0.68707769]]\n",
      "[[0.68387261]]\n",
      "[[0.68066925]]\n",
      "[[0.67746863]]\n",
      "[[0.67427179]]\n",
      "[[0.67107976]]\n",
      "[[0.66789361]]\n",
      "[[0.66471442]]\n",
      "[[0.66154325]]\n",
      "[[0.6583812]]\n",
      "[[0.65522936]]\n",
      "[[0.65208884]]\n",
      "[[0.64896074]]\n",
      "[[0.64584618]]\n",
      "[[0.64274627]]\n",
      "[[0.63966211]]\n",
      "[[0.63659482]]\n",
      "[[0.63354551]]\n",
      "[[0.63051527]]\n",
      "[[0.6275052]]\n",
      "[[0.62451639]]\n",
      "[[0.62154992]]\n",
      "[[0.61860686]]\n",
      "[[0.61568826]]\n",
      "[[0.61279516]]\n",
      "[[0.60992859]]\n",
      "[[0.60708957]]\n",
      "[[0.60427907]]\n",
      "[[0.60149808]]\n",
      "[[0.59874754]]\n",
      "[[0.59602838]]\n",
      "[[0.59334152]]\n",
      "[[0.59068781]]\n",
      "[[0.58806813]]\n",
      "[[0.58548329]]\n",
      "[[0.58293409]]\n",
      "[[0.58042129]]\n",
      "[[0.57794563]]\n",
      "[[0.57550781]]\n",
      "[[0.57310849]]\n",
      "[[0.57074831]]\n",
      "[[0.56842787]]\n",
      "[[0.56614771]]\n",
      "[[0.56390836]]\n",
      "[[0.56171031]]\n",
      "[[0.55955398]]\n",
      "[[0.5574398]]\n",
      "[[0.5553681]]\n",
      "[[0.55333922]]\n",
      "[[0.55135343]]\n",
      "[[0.54941097]]\n",
      "[[0.54751202]]\n",
      "[[0.54565673]]\n",
      "[[0.54384521]]\n",
      "[[0.54207752]]\n",
      "[[0.54035368]]\n",
      "[[0.53867367]]\n",
      "[[0.53703742]]\n",
      "[[0.53544482]]\n",
      "[[0.53389573]]\n",
      "[[0.53238996]]\n",
      "[[0.53092727]]\n",
      "[[0.5295074]]\n",
      "[[0.52813005]]\n",
      "[[0.52679487]]\n",
      "[[0.52550147]]\n",
      "[[0.52424946]]\n",
      "[[0.52303837]]\n",
      "[[0.52186773]]\n",
      "[[0.52073703]]\n",
      "[[0.51964572]]\n",
      "[[0.51859324]]\n",
      "[[0.51757899]]\n",
      "[[0.51660236]]\n",
      "[[0.51566269]]\n",
      "[[0.51475933]]\n",
      "[[0.51389158]]\n",
      "[[0.51305875]]\n",
      "[[0.51226011]]\n",
      "[[0.51149492]]\n",
      "[[0.51076245]]\n",
      "[[0.51006191]]\n",
      "[[0.50939255]]\n",
      "[[0.50875357]]\n",
      "[[0.5081442]]\n",
      "[[0.50756363]]\n",
      "[[0.50701108]]\n",
      "[[0.50648572]]\n",
      "[[0.50598677]]\n",
      "[[0.50551342]]\n",
      "[[0.50506487]]\n",
      "[[0.50464031]]\n",
      "[[0.50423896]]\n",
      "[[0.50386002]]\n",
      "[[0.5035027]]\n",
      "[[0.50316623]]\n",
      "[[0.50284984]]\n",
      "[[0.50255276]]\n",
      "[[0.50227425]]\n"
     ]
    }
   ],
   "source": [
    "from model.layers.dense import Dense\n",
    "from model.layers.output import Output\n",
    "from model.layers.input import Input\n",
    "from model.optimizers.adam import Adam\n",
    "import numpy as np\n",
    "\n",
    "adam = Adam()\n",
    "layer1 = Input((2,0), (2,0), 2, np.array([[0.1,0.4], [0.8,0.6]]))\n",
    "layer2 = Dense((2,0), (1,0), 2, np.array([[0.3], [0.9]]))\n",
    "layer2.compile(optimizer=adam)\n",
    "layer3 = Output((1,0), (1,0), np.array([[0.5]]), 'relu', '')\n",
    "\n",
    "input = np.array([[0.35,0.9]]).T\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "for i in range(100):\n",
    "    final_out = layer3.forward(layer2.forward(layer1.forward(input)))\n",
    "    print(final_out)\n",
    "    layer1.backward(layer2.backward(layer3.backward(final_out)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model that has convolutional layers and fully connected layers\n",
    "### but only do backprop on the fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n",
      "[[0.57707703]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from model.layers.conv2d import Conv2D\n",
    "from model.layers.output import Output\n",
    "from model.layers.input import Input\n",
    "from model.optimizers.adam import Adam\n",
    "from model.layers.flatten import Flatten\n",
    "from model.layers.dense import Dense\n",
    "import numpy as np\n",
    "\n",
    "adam = Adam()\n",
    "input = np.array([[\n",
    "    [1,2,3,4,5],\n",
    "    [6,7,8,9,10],\n",
    "    [11,12,13,14,15],\n",
    "    [16,17,18,19,20],\n",
    "    [21,22,23,24,25]\n",
    "],\n",
    "[\n",
    "    [30, 31, 32, 33, 34],\n",
    "    [35, 36, 37, 38, 39],\n",
    "    [40, 41, 42, 43, 44],\n",
    "    [45, 46, 47, 48, 49],\n",
    "    [50, 51, 52, 53, 54]]\n",
    "])\n",
    "\n",
    "\n",
    "convLayer = Conv2D(input_shape=(2,5,5), input.shape=(2,3,3), filters=2, kernel_size=3)\n",
    "flattenLayer = Flatten(input_shape=(2,3,3), input.shape=(18,1), activation='relu')\n",
    "flattenLayer.forward(convLayer.forward(input))\n",
    "\n",
    "layer2 = Dense(input_shape=(18,1), input.shape=(5,1))\n",
    "layer3 = Dense(input_shape=(5,1), input.shape=(1,1))\n",
    "\n",
    "layer2.compile(optimizer='adam')\n",
    "layer3.compile(optimizer='adam')\n",
    "output = Output((1,1), (1,1), np.array([[0.50]]), 'relu', '')\n",
    "\n",
    "for i in range(1000):\n",
    "     final_out = output.forward(layer3.forward(layer2.forward(flattenLayer.forward(convLayer.forward(input)))))\n",
    "     print(final_out)\n",
    "     # train fully-connected portion\n",
    "     #layer2.backward(layer3.backward(output.backward(final_out)))\n",
    "     \n",
    "     # train convolutional portion:\n",
    "     \n",
    "\n",
    "#layer3.forward(layer2.forward(flattenLayer.forward(convLayer.forward(input))))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train a network that has convolutional layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50261229]]\n",
      "[[0.5023452]]\n",
      "[[0.50207809]]\n",
      "[[0.5017912]]\n",
      "[[0.50154698]]\n",
      "[[0.50127819]]\n",
      "[[0.5010285]]\n",
      "[[0.50076478]]\n",
      "[[0.50051046]]\n",
      "[[0.50026073]]\n",
      "[[0.50000511]]\n",
      "[[0.49975446]]\n",
      "[[0.49950309]]\n",
      "[[0.4992524]]\n",
      "[[0.49900218]]\n",
      "[[0.49875242]]\n",
      "[[0.4985029]]\n",
      "[[0.49825344]]\n",
      "[[0.49800404]]\n",
      "[[0.4977547]]\n",
      "[[0.49750543]]\n",
      "[[0.49725623]]\n",
      "[[0.4970071]]\n",
      "[[0.49675804]]\n",
      "[[0.49650906]]\n",
      "[[0.49626016]]\n",
      "[[0.49601133]]\n",
      "[[0.49576259]]\n",
      "[[0.49551393]]\n",
      "[[0.49526536]]\n",
      "[[0.49501688]]\n",
      "[[0.49476848]]\n",
      "[[0.49452018]]\n",
      "[[0.49427196]]\n",
      "[[0.49402384]]\n",
      "[[0.49377582]]\n",
      "[[0.49352788]]\n",
      "[[0.49328005]]\n",
      "[[0.49303231]]\n",
      "[[0.49278467]]\n",
      "[[0.49253713]]\n",
      "[[0.49228968]]\n",
      "[[0.49204234]]\n",
      "[[0.4917951]]\n",
      "[[0.49154796]]\n",
      "[[0.49130093]]\n",
      "[[0.49105399]]\n",
      "[[0.49080716]]\n",
      "[[0.49056043]]\n",
      "[[0.49031381]]\n",
      "[[0.49006729]]\n",
      "[[0.48982088]]\n",
      "[[0.48957457]]\n",
      "[[0.48932836]]\n",
      "[[0.48908226]]\n",
      "[[0.48883627]]\n",
      "[[0.48859038]]\n",
      "[[0.4883446]]\n",
      "[[0.48809893]]\n",
      "[[0.48785336]]\n",
      "[[0.48760789]]\n",
      "[[0.48736253]]\n",
      "[[0.48711728]]\n",
      "[[0.48687214]]\n",
      "[[0.4866271]]\n",
      "[[0.48638217]]\n",
      "[[0.48613734]]\n",
      "[[0.48589262]]\n",
      "[[0.48564801]]\n",
      "[[0.4854035]]\n",
      "[[0.4851591]]\n",
      "[[0.4849148]]\n",
      "[[0.48467062]]\n",
      "[[0.48442653]]\n",
      "[[0.48418256]]\n",
      "[[0.48393868]]\n",
      "[[0.48369492]]\n",
      "[[0.48345126]]\n",
      "[[0.48320771]]\n",
      "[[0.48296426]]\n",
      "[[0.48272091]]\n",
      "[[0.48247768]]\n",
      "[[0.48223454]]\n",
      "[[0.48199152]]\n",
      "[[0.48174859]]\n",
      "[[0.48150578]]\n",
      "[[0.48126306]]\n",
      "[[0.48102045]]\n",
      "[[0.48077795]]\n",
      "[[0.48053555]]\n",
      "[[0.48029326]]\n",
      "[[0.48005106]]\n",
      "[[0.47980898]]\n",
      "[[0.47956699]]\n",
      "[[0.47932511]]\n",
      "[[0.47908334]]\n",
      "[[0.47884167]]\n",
      "[[0.4786001]]\n",
      "[[0.47835863]]\n",
      "[[0.47811727]]\n",
      "[[0.47787601]]\n",
      "[[0.47763485]]\n",
      "[[0.4773938]]\n",
      "[[0.47715284]]\n",
      "[[0.47691199]]\n",
      "[[0.47667125]]\n",
      "[[0.4764306]]\n",
      "[[0.47619006]]\n",
      "[[0.47594962]]\n",
      "[[0.47570928]]\n",
      "[[0.47546904]]\n",
      "[[0.4752289]]\n",
      "[[0.47498887]]\n",
      "[[0.47474894]]\n",
      "[[0.4745091]]\n",
      "[[0.47426937]]\n",
      "[[0.47402974]]\n",
      "[[0.47379021]]\n",
      "[[0.47355078]]\n",
      "[[0.47331145]]\n",
      "[[0.47307222]]\n",
      "[[0.47283309]]\n",
      "[[0.47259406]]\n",
      "[[0.47235513]]\n",
      "[[0.4721163]]\n",
      "[[0.47187757]]\n",
      "[[0.47163894]]\n",
      "[[0.47140041]]\n",
      "[[0.47116198]]\n",
      "[[0.47092365]]\n",
      "[[0.47068541]]\n",
      "[[0.47044728]]\n",
      "[[0.47020924]]\n",
      "[[0.4699713]]\n",
      "[[0.46973347]]\n",
      "[[0.46949572]]\n",
      "[[0.46925808]]\n",
      "[[0.46902054]]\n",
      "[[0.46878309]]\n",
      "[[0.46854574]]\n",
      "[[0.46830849]]\n",
      "[[0.46807133]]\n",
      "[[0.46783428]]\n",
      "[[0.46759732]]\n",
      "[[0.46736046]]\n",
      "[[0.46712369]]\n",
      "[[0.46688702]]\n",
      "[[0.46665045]]\n",
      "[[0.46641397]]\n",
      "[[0.4661776]]\n",
      "[[0.46594131]]\n",
      "[[0.46570513]]\n",
      "[[0.46546904]]\n",
      "[[0.46523304]]\n",
      "[[0.46499715]]\n",
      "[[0.46476134]]\n",
      "[[0.46452564]]\n",
      "[[0.46429003]]\n",
      "[[0.46405451]]\n",
      "[[0.46381909]]\n",
      "[[0.46358377]]\n",
      "[[0.46334853]]\n",
      "[[0.4631134]]\n",
      "[[0.46287836]]\n",
      "[[0.46264341]]\n",
      "[[0.46240856]]\n",
      "[[0.46217381]]\n",
      "[[0.46193914]]\n",
      "[[0.46170458]]\n",
      "[[0.4614701]]\n",
      "[[0.46123572]]\n",
      "[[0.46100143]]\n",
      "[[0.46076724]]\n",
      "[[0.46053314]]\n",
      "[[0.46029914]]\n",
      "[[0.46006523]]\n",
      "[[0.45983141]]\n",
      "[[0.45959768]]\n",
      "[[0.45936405]]\n",
      "[[0.45913051]]\n",
      "[[0.45889706]]\n",
      "[[0.45866371]]\n",
      "[[0.45843045]]\n",
      "[[0.45819728]]\n",
      "[[0.4579642]]\n",
      "[[0.45773122]]\n",
      "[[0.45749833]]\n",
      "[[0.45726553]]\n",
      "[[0.45703282]]\n",
      "[[0.45680021]]\n",
      "[[0.45656768]]\n",
      "[[0.45633525]]\n",
      "[[0.45610291]]\n",
      "[[0.45587066]]\n",
      "[[0.4556385]]\n",
      "[[0.45540643]]\n",
      "[[0.45517446]]\n",
      "[[0.45494258]]\n",
      "[[0.45471078]]\n",
      "[[0.45447908]]\n",
      "[[0.45424747]]\n",
      "[[0.45401595]]\n",
      "[[0.45378451]]\n",
      "[[0.45355317]]\n",
      "[[0.45332192]]\n",
      "[[0.45309077]]\n",
      "[[0.4528597]]\n",
      "[[0.45262872]]\n",
      "[[0.45239783]]\n",
      "[[0.45216703]]\n",
      "[[0.45193632]]\n",
      "[[0.4517057]]\n",
      "[[0.45147517]]\n",
      "[[0.45124473]]\n",
      "[[0.45101437]]\n",
      "[[0.45078411]]\n",
      "[[0.45055394]]\n",
      "[[0.45032385]]\n",
      "[[0.45009386]]\n",
      "[[0.44986395]]\n",
      "[[0.44963414]]\n",
      "[[0.44940441]]\n",
      "[[0.44917477]]\n",
      "[[0.44894522]]\n",
      "[[0.44871575]]\n",
      "[[0.44848638]]\n",
      "[[0.44825709]]\n",
      "[[0.44802789]]\n",
      "[[0.44779879]]\n",
      "[[0.44756976]]\n",
      "[[0.44734083]]\n",
      "[[0.44711198]]\n",
      "[[0.44688323]]\n",
      "[[0.44665456]]\n",
      "[[0.44642597]]\n",
      "[[0.44619748]]\n",
      "[[0.44596907]]\n",
      "[[0.44574075]]\n",
      "[[0.44551252]]\n",
      "[[0.44528437]]\n",
      "[[0.44505632]]\n",
      "[[0.44482834]]\n",
      "[[0.44460046]]\n",
      "[[0.44437266]]\n",
      "[[0.44414495]]\n",
      "[[0.44391733]]\n",
      "[[0.44368979]]\n",
      "[[0.44346234]]\n",
      "[[0.44323498]]\n",
      "[[0.4430077]]\n",
      "[[0.44278051]]\n",
      "[[0.44255341]]\n",
      "[[0.44232639]]\n",
      "[[0.44209946]]\n",
      "[[0.44187261]]\n",
      "[[0.44164585]]\n",
      "[[0.44141918]]\n",
      "[[0.44119259]]\n",
      "[[0.44096609]]\n",
      "[[0.44073967]]\n",
      "[[0.44051334]]\n",
      "[[0.4402871]]\n",
      "[[0.44006094]]\n",
      "[[0.43983487]]\n",
      "[[0.43960888]]\n",
      "[[0.43938298]]\n",
      "[[0.43915716]]\n",
      "[[0.43893143]]\n",
      "[[0.43870578]]\n",
      "[[0.43848022]]\n",
      "[[0.43825474]]\n",
      "[[0.43802935]]\n",
      "[[0.43780405]]\n",
      "[[0.43757882]]\n",
      "[[0.43735369]]\n",
      "[[0.43712864]]\n",
      "[[0.43690367]]\n",
      "[[0.43667879]]\n",
      "[[0.43645399]]\n",
      "[[0.43622928]]\n",
      "[[0.43600465]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from model.layers.conv2d import Conv2D\n",
    "from model.layers.output import Output\n",
    "from model.layers.flatten import Flatten\n",
    "from model.layers.dense import Dense\n",
    "from model.layers.maxpool2d import MaxPool2D\n",
    "from model.layers.dropout import ConvDropout, DenseDropout\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "input = np.random.uniform(low=-1, high=1, size=(2,12,12))\n",
    "# make convolutional layers\n",
    "convLayer1 = Conv2D(input_shape=(2,12,12), output_shape=(4,10,10), filters=4, kernel_size=3, activation='relu')\n",
    "convLayer1.compile(optimizer='adam')\n",
    "\n",
    "convDropoutLayer = ConvDropout(input_shape=(4,10,10), output_shape=(4,10,10), dropout_rate=0.5)\n",
    "\n",
    "convLayer2 = Conv2D(input_shape=(4,10,10), output_shape=(10,7,7), filters=10, kernel_size=4, activation='relu')\n",
    "convLayer2.compile(optimizer='adam')\n",
    "\n",
    "poolingLayer = MaxPool2D(input_shape=(10,7,7), output_shape=(10,3,3), pool_size=(5,5))\n",
    "\n",
    "convLayer3 = Conv2D(input_shape=(10,3,3), output_shape=(1,3,3), filters=1, kernel_size=1, activation='relu')\n",
    "convLayer3.compile(optimizer='adam')\n",
    "\n",
    "# make flatten layer\n",
    "flattenLayer = Flatten(input_shape=(1,3,3), output_shape=(9,1), activation='relu')\n",
    "\n",
    "# make fully connected layers\n",
    "layer2 = Dense(input_shape=(9,1), output_shape=(5,1), activation='relu')\n",
    "layer2.compile(optimizer='adam')\n",
    "\n",
    "denseDropoutLayer = DenseDropout(input_shape=(5,1), output_shape=(5,1), dropout_rate=0.5)\n",
    "\n",
    "layer3 = Dense(input_shape=(5,1), output_shape=(1,1), activation='relu')\n",
    "layer3.compile(optimizer='adam')\n",
    "\n",
    "# make output\n",
    "output = Output((1,1), (1,1), np.array([[0.24]]), 'sigmoid', '')\n",
    "\n",
    "iters = 2000\n",
    "for i in range(iters):\n",
    "     conv_out = convLayer3.forward(poolingLayer.forward(convLayer2.forward(convDropoutLayer.forward(convLayer1.forward(input)))))\n",
    "     final_out = output.forward(layer3.forward(denseDropoutLayer.forward(layer2.forward(flattenLayer.forward(conv_out)))))\n",
    "     print(final_out)\n",
    "     # train fully-connected portion\n",
    "     fully_connected_backprop = layer2.backward(denseDropoutLayer.backward(layer3.backward(output.backward(final_out))))\n",
    "     # train convolutional portion:\n",
    "     convLayer1.backward(convDropoutLayer.backward(convLayer2.backward(poolingLayer.backward(convLayer3.backward(flattenLayer.backward(fully_connected_backprop))))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiple channel example of maxpooling backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray([[\n\u001b[0;32m      2\u001b[0m     [\u001b[38;5;241m111\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m],\n\u001b[0;32m      3\u001b[0m     [\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      4\u001b[0m     [\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m13\u001b[39m,\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m15\u001b[39m],\n\u001b[0;32m      5\u001b[0m     [\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m17\u001b[39m,\u001b[38;5;241m18\u001b[39m,\u001b[38;5;241m19\u001b[39m,\u001b[38;5;241m20\u001b[39m],\n\u001b[0;32m      6\u001b[0m     [\u001b[38;5;241m21\u001b[39m,\u001b[38;5;241m22\u001b[39m,\u001b[38;5;241m23\u001b[39m,\u001b[38;5;241m24\u001b[39m,\u001b[38;5;241m25\u001b[39m]\n\u001b[0;32m      7\u001b[0m ],\n\u001b[0;32m      8\u001b[0m [\n\u001b[0;32m      9\u001b[0m     [\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m31\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m33\u001b[39m, \u001b[38;5;241m34\u001b[39m],\n\u001b[0;32m     10\u001b[0m     [\u001b[38;5;241m35\u001b[39m, \u001b[38;5;241m36\u001b[39m, \u001b[38;5;241m37\u001b[39m, \u001b[38;5;241m38\u001b[39m, \u001b[38;5;241m39\u001b[39m],\n\u001b[0;32m     11\u001b[0m     [\u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m41\u001b[39m, \u001b[38;5;241m42\u001b[39m, \u001b[38;5;241m43\u001b[39m, \u001b[38;5;241m44\u001b[39m],\n\u001b[0;32m     12\u001b[0m     [\u001b[38;5;241m45\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m44\u001b[39m, \u001b[38;5;241m488\u001b[39m, \u001b[38;5;241m49\u001b[39m],\n\u001b[0;32m     13\u001b[0m     [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m51\u001b[39m, \u001b[38;5;241m52\u001b[39m, \u001b[38;5;241m53\u001b[39m, \u001b[38;5;241m54\u001b[39m]]\n\u001b[0;32m     14\u001b[0m ])\n\u001b[0;32m     16\u001b[0m pool_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     17\u001b[0m stride \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "input = np.array([[\n",
    "    [111,2,3,4,5],\n",
    "    [6,7,8,9,10],\n",
    "    [11,12,13,14,15],\n",
    "    [16,17,18,19,20],\n",
    "    [21,22,23,24,25]\n",
    "],\n",
    "[\n",
    "    [30, 31, 32, 33, 34],\n",
    "    [35, 36, 37, 38, 39],\n",
    "    [40, 41, 42, 43, 44],\n",
    "    [45, 4, 44, 488, 49],\n",
    "    [50, 51, 52, 53, 54]]\n",
    "])\n",
    "\n",
    "pool_size = (3,3)\n",
    "stride = 1\n",
    "output_size = int((input.shape[1] - pool_size[0])/stride) + 1\n",
    "output = np.zeros((input.shape[0], output_size, output_size))\n",
    "positions = np.zeros(output.shape, dtype=(int, 3))\n",
    "for i in range(output_size): # rows\n",
    "    for j in range(output_size): # columns\n",
    "        row_start = i*stride\n",
    "        row_end = row_start + pool_size[0]\n",
    "        col_start = j*stride\n",
    "        col_end = col_start + pool_size[1]\n",
    "        for k in range(input.shape[0]): # channels\n",
    "            frame = input[k,row_start:row_end, col_start:col_end]\n",
    "            output[k,i,j] = np.max(frame)\n",
    "            # get the spot in the frame with the max value\n",
    "            positions[k,i,j,1:] = np.unravel_index(np.argmax(frame), frame.shape)\n",
    "            # add channel to position\n",
    "            positions[k,i,j,0] = k\n",
    "            # add offsets to get the spot in the output matrix with max value of this frame\n",
    "            positions[k,i,j,1] += row_start\n",
    "            positions[k,i,j,2] += col_start\n",
    "            \n",
    "output_grads = np.array(\n",
    "    [\n",
    "        [\n",
    "            [1, 2, 3],\n",
    "            [4,5,6],\n",
    "            [7,8,9]\n",
    "        ],\n",
    "\n",
    "        [\n",
    "            [10,11,12],\n",
    "            [13,14,15],\n",
    "            [16,17,18]\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "r_val = np.zeros(input.shape)\n",
    "channel_pos = positions[:, :, :, 0]\n",
    "row_pos = positions[:, :, :, 1]\n",
    "col_pos = positions[:, :, :, 2]\n",
    "r_val[channel_pos, row_pos, col_pos] = output_grads\n",
    "print(input)\n",
    "print(output)\n",
    "print(r_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple channel example of dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1]\n",
      " [1 1 0 3 1 4 1 1 0 0 4 4 0 2 1 4 0 0 0 1 2 1 0 0 4]\n",
      " [2 3 1 0 0 4 0 2 0 0 3 2 1 3 0 3 3 0 1 0 4 4 3 4 1]]\n",
      "[[[  0   0   3   0   0]\n",
      "  [  0   7   0   0  10]\n",
      "  [ 11  12  13   0  15]\n",
      "  [ 16  17  18  19  20]\n",
      "  [ 21  22  23  24   0]]\n",
      "\n",
      " [[  0   0  32   0  34]\n",
      "  [  0  36   0  38   0]\n",
      "  [ 40  41  42  43   0]\n",
      "  [  0   4  44 488  49]\n",
      "  [ 50   0   0   0  54]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   3,   0,   0],\n",
       "        [  0,   7,   0,   0,  10],\n",
       "        [ 11,  12,  13,   0,  15],\n",
       "        [ 16,  17,  18,  19,  20],\n",
       "        [ 21,  22,  23,  24,   0]],\n",
       "\n",
       "       [[  0,   0,  32,   0,  34],\n",
       "        [  0,  36,   0,  38,   0],\n",
       "        [ 40,  41,  42,  43,   0],\n",
       "        [  0,   4,  44, 488,  49],\n",
       "        [ 50,   0,   0,   0,  54]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = np.array([[\n",
    "    [111,2,3,4,5],\n",
    "    [6,7,8,9,10],\n",
    "    [11,12,13,14,15],\n",
    "    [16,17,18,19,20],\n",
    "    [21,22,23,24,25]\n",
    "],\n",
    "[\n",
    "    [30, 31, 32, 33, 34],\n",
    "    [35, 36, 37, 38, 39],\n",
    "    [40, 41, 42, 43, 44],\n",
    "    [45, 4, 44, 488, 49],\n",
    "    [50, 51, 52, 53, 54]]\n",
    "])\n",
    "input_shape = input.shape\n",
    "dropout_rate = 0.5\n",
    "\n",
    "dropout_num = int(input_shape[0] * input_shape[1] * input_shape[2] * dropout_rate)\n",
    "z_coord = np.random.randint(low=0, high=input.shape[0], size=dropout_num)\n",
    "x_coord = np.random.randint(low=0, high=input_shape[1], size=dropout_num)\n",
    "y_coord = np.random.randint(low=0, high=input_shape[2], size=dropout_num)\n",
    "positions = np.stack((z_coord, x_coord, y_coord))\n",
    "print(positions)\n",
    "input_copy = np.copy(input)\n",
    "input_copy[z_coord,x_coord,y_coord] = 0.0\n",
    "print(input_copy)\n",
    "\n",
    "\n",
    "output_grads = input\n",
    "# this is a matrix of the channel coordinates for each of the max values that we outputed upon forward prop\n",
    "channel_pos = positions[0]\n",
    "# and a matrix for the row coordinates\n",
    "row_pos = positions[1]\n",
    "# and a matrix for the col coordinates\n",
    "col_pos = positions[2]\n",
    "output_grads[channel_pos, row_pos, col_pos] = 0.0\n",
    "output_grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50264192]]\n",
      "[[0.50236363]]\n",
      "[[0.50208889]]\n",
      "[[0.50181763]]\n",
      "[[0.50154972]]\n",
      "[[0.50128499]]\n",
      "[[0.50102326]]\n",
      "[[0.50076432]]\n",
      "[[0.50050792]]\n",
      "[[0.50025379]]\n",
      "[[0.50000161]]\n",
      "[[0.49975104]]\n",
      "[[0.49950131]]\n",
      "[[0.49925164]]\n",
      "[[0.49900201]]\n",
      "[[0.49875244]]\n",
      "[[0.49850293]]\n",
      "[[0.49825347]]\n",
      "[[0.49800407]]\n",
      "[[0.49775473]]\n",
      "[[0.49750547]]\n",
      "[[0.49725627]]\n",
      "[[0.49700714]]\n",
      "[[0.49675808]]\n",
      "[[0.49650911]]\n",
      "[[0.4962602]]\n",
      "[[0.49601138]]\n",
      "[[0.49576264]]\n",
      "[[0.49551399]]\n",
      "[[0.49526542]]\n",
      "[[0.49501694]]\n",
      "[[0.49476854]]\n",
      "[[0.49452024]]\n",
      "[[0.49427203]]\n",
      "[[0.49402391]]\n",
      "[[0.49377588]]\n",
      "[[0.49352795]]\n",
      "[[0.49328012]]\n",
      "[[0.49303238]]\n",
      "[[0.49278474]]\n",
      "[[0.4925372]]\n",
      "[[0.49228976]]\n",
      "[[0.49204242]]\n",
      "[[0.49179518]]\n",
      "[[0.49154804]]\n",
      "[[0.491301]]\n",
      "[[0.49105407]]\n",
      "[[0.49080724]]\n",
      "[[0.49056052]]\n",
      "[[0.49031389]]\n",
      "[[0.49006738]]\n",
      "[[0.48982096]]\n",
      "[[0.48957465]]\n",
      "[[0.48932845]]\n",
      "[[0.48908235]]\n",
      "[[0.48883636]]\n",
      "[[0.48859047]]\n",
      "[[0.48834469]]\n",
      "[[0.48809902]]\n",
      "[[0.48785345]]\n",
      "[[0.48760798]]\n",
      "[[0.48736263]]\n",
      "[[0.48711738]]\n",
      "[[0.48687223]]\n",
      "[[0.48662719]]\n",
      "[[0.48638226]]\n",
      "[[0.48613744]]\n",
      "[[0.48589272]]\n",
      "[[0.48564811]]\n",
      "[[0.4854036]]\n",
      "[[0.4851592]]\n",
      "[[0.4849149]]\n",
      "[[0.48467072]]\n",
      "[[0.48442663]]\n",
      "[[0.48418266]]\n",
      "[[0.48393879]]\n",
      "[[0.48369502]]\n",
      "[[0.48345136]]\n",
      "[[0.48320781]]\n",
      "[[0.48296436]]\n",
      "[[0.48272102]]\n",
      "[[0.48247778]]\n",
      "[[0.48223465]]\n",
      "[[0.48199162]]\n",
      "[[0.4817487]]\n",
      "[[0.48150588]]\n",
      "[[0.48126317]]\n",
      "[[0.48102056]]\n",
      "[[0.48077806]]\n",
      "[[0.48053566]]\n",
      "[[0.48029337]]\n",
      "[[0.48005117]]\n",
      "[[0.47980909]]\n",
      "[[0.4795671]]\n",
      "[[0.47932523]]\n",
      "[[0.47908345]]\n",
      "[[0.47884178]]\n",
      "[[0.47860021]]\n",
      "[[0.47835874]]\n",
      "[[0.47811738]]\n",
      "[[0.47787612]]\n",
      "[[0.47763496]]\n",
      "[[0.47739391]]\n",
      "[[0.47715296]]\n",
      "[[0.47691211]]\n",
      "[[0.47667136]]\n",
      "[[0.47643072]]\n",
      "[[0.47619018]]\n",
      "[[0.47594973]]\n",
      "[[0.4757094]]\n",
      "[[0.47546916]]\n",
      "[[0.47522902]]\n",
      "[[0.47498899]]\n",
      "[[0.47474905]]\n",
      "[[0.47450922]]\n",
      "[[0.47426949]]\n",
      "[[0.47402986]]\n",
      "[[0.47379033]]\n",
      "[[0.4735509]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m final_out \u001b[38;5;241m=\u001b[39msequential\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_out)\n\u001b[0;32m---> 54\u001b[0m \u001b[43msequential\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_out\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/final_cnn/group_2/CNN-Project/sequential.py:31\u001b[0m, in \u001b[0;36mSequential.backward\u001b[0;34m(self, output, index)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m     30\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[index]\u001b[38;5;241m.\u001b[39mbackward(output)\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/final_cnn/group_2/CNN-Project/sequential.py:31\u001b[0m, in \u001b[0;36mSequential.backward\u001b[0;34m(self, output, index)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m     30\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[index]\u001b[38;5;241m.\u001b[39mbackward(output)\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping similar frames: Sequential.backward at line 31 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/final_cnn/group_2/CNN-Project/sequential.py:31\u001b[0m, in \u001b[0;36mSequential.backward\u001b[0;34m(self, output, index)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m     30\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[index]\u001b[38;5;241m.\u001b[39mbackward(output)\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/final_cnn/group_2/CNN-Project/sequential.py:30\u001b[0m, in \u001b[0;36mSequential.backward\u001b[0;34m(self, output, index)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m---> 30\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(grad, index \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/final_cnn/group_2/CNN-Project/model/layers/conv2d.py:48\u001b[0m, in \u001b[0;36mConv2D.backward\u001b[0;34m(self, output_grads)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblame \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblame\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblame[j] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39marray([\u001b[43mkern\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannel_blame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_grad\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m kern, output_grad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernels, output_grads)]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# for each kernel and it's associated output gradient, update the weights\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kern, output_grad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernels, output_grads):\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/final_cnn/group_2/CNN-Project/kernel.py:33\u001b[0m, in \u001b[0;36mKernel.channel_blame\u001b[0;34m(self, channel, grad_output)\u001b[0m\n\u001b[1;32m     31\u001b[0m padded_grad_output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(grad_output, pad_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)[np\u001b[38;5;241m.\u001b[39mnewaxis, :, :]\n\u001b[1;32m     32\u001b[0m channel_weight_rot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrot90(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[channel], k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)[np\u001b[38;5;241m.\u001b[39mnewaxis, :, :]\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mKernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_grad_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_weight_rot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/final_cnn/group_2/CNN-Project/kernel.py:63\u001b[0m, in \u001b[0;36mKernel._convolve\u001b[0;34m(input, weights, stride)\u001b[0m\n\u001b[1;32m     61\u001b[0m         col_start \u001b[38;5;241m=\u001b[39m j\u001b[38;5;241m*\u001b[39mstride\n\u001b[1;32m     62\u001b[0m         col_end \u001b[38;5;241m=\u001b[39m col_start \u001b[38;5;241m+\u001b[39m weights\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m---> 63\u001b[0m         output[i,j] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mrow_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcol_end\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from model.layers.conv2d import Conv2D\n",
    "from model.layers.output import Output\n",
    "from model.layers.flatten import Flatten\n",
    "from model.layers.dense import Dense\n",
    "from model.layers.maxpool2d import MaxPool2D\n",
    "from model.layers.dropout import ConvDropout, DenseDropout\n",
    "import numpy as np\n",
    "from sequential import Sequential\n",
    "\n",
    "\n",
    "from model.layers.conv2d import Conv2D\n",
    "from model.layers.output import Output\n",
    "from model.layers.flatten import Flatten\n",
    "from model.layers.dense import Dense\n",
    "from model.layers.maxpool2d import MaxPool2D\n",
    "from model.layers.dropout import ConvDropout, DenseDropout\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "input = np.random.uniform(low=-1, high=1, size=(2,12,12))\n",
    "# make convolutional layers\n",
    "convLayer1 = Conv2D(input_shape=(2,12,12), output_shape=(4,10,10), filters=4, kernel_size=3, activation='relu')\n",
    "convDropoutLayer = ConvDropout(input_shape=(4,10,10), output_shape=(4,10,10), dropout_rate=0.5)\n",
    "convLayer2 = Conv2D(input_shape=(4,10,10), output_shape=(10,7,7), filters=10, kernel_size=4, activation='relu')\n",
    "poolingLayer = MaxPool2D(input_shape=(10,7,7), output_shape=(10,3,3), pool_size=(5,5))\n",
    "convLayer3 = Conv2D(input_shape=(10,3,3), output_shape=(1,3,3), filters=1, kernel_size=1, activation='relu')\n",
    "\n",
    "# make flatten layer\n",
    "flattenLayer = Flatten(input_shape=(1,3,3), output_shape=(9,1), activation='relu')\n",
    "layer2 = Dense(input_shape=(9,1), output_shape=(5,1), activation='relu')\n",
    "denseDropoutLayer = DenseDropout(input_shape=(5,1), output_shape=(5,1), dropout_rate=0.5)\n",
    "layer3 = Dense(input_shape=(5,1), output_shape=(1,1), activation='relu')\n",
    "# make output\n",
    "output = Output((1,1), (1,1), np.array([[0.24]]), 'sigmoid', '')\n",
    "input = np.random.uniform(low=-1, high=1, size=(2,12,12))\n",
    "sequential = Sequential()\n",
    "\n",
    "\n",
    "sequential.add(convLayer1)\n",
    "sequential.add(convLayer2)\n",
    "sequential.add(poolingLayer)\n",
    "sequential.add(convLayer3)\n",
    "sequential.add(flattenLayer)\n",
    "sequential.add(layer2)\n",
    "sequential.add(layer3)\n",
    "sequential.add(output)\n",
    "\n",
    "sequential.compile('adam')\n",
    "\n",
    "\n",
    "for i in range(150):\n",
    "    final_out =sequential.forward(input)\n",
    "    print(final_out)\n",
    "    sequential.backward(final_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No image files found in the specified directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from sequential import Sequential\n",
    "path = './sub_data'  #absolute path \n",
    "\n",
    "sequential = Sequential()\n",
    "train_value,train_target, validation_value , validation_target =sequential.preprocess_dataset(path,'c')\n",
    "#print(train_value)\n",
    "#print(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50264177]]\n",
      "[[0.50236332]]\n",
      "[[0.50208851]]\n",
      "[[0.50181724]]\n",
      "[[0.50154934]]\n",
      "[[0.50128463]]\n",
      "[[0.50102293]]\n",
      "[[0.500764]]\n",
      "[[0.5005076]]\n",
      "[[0.50025343]]\n",
      "[[0.50000119]]\n",
      "[[0.49975054]]\n",
      "[[0.49950068]]\n",
      "[[0.49925085]]\n",
      "[[0.49900105]]\n",
      "[[0.49875127]]\n",
      "[[0.49850152]]\n",
      "[[0.4982518]]\n",
      "[[0.49800212]]\n",
      "[[0.49775246]]\n",
      "[[0.49750285]]\n",
      "[[0.49725326]]\n",
      "[[0.49700372]]\n",
      "[[0.49675422]]\n",
      "[[0.49650475]]\n",
      "[[0.49625533]]\n",
      "[[0.49600595]]\n",
      "[[0.49575661]]\n",
      "[[0.49550732]]\n",
      "[[0.49525807]]\n",
      "[[0.49500887]]\n",
      "[[0.49475972]]\n",
      "[[0.49451061]]\n",
      "[[0.49426156]]\n",
      "[[0.49401255]]\n",
      "[[0.49376359]]\n",
      "[[0.49351469]]\n",
      "[[0.49326584]]\n",
      "[[0.49301703]]\n",
      "[[0.49276829]]\n",
      "[[0.49251959]]\n",
      "[[0.49227095]]\n",
      "[[0.49202236]]\n",
      "[[0.49177383]]\n",
      "[[0.49152535]]\n",
      "[[0.49127693]]\n",
      "[[0.49102856]]\n",
      "[[0.49078025]]\n",
      "[[0.49053199]]\n",
      "[[0.4902838]]\n",
      "[[0.49003565]]\n",
      "[[0.48978757]]\n",
      "[[0.48953954]]\n",
      "[[0.48929157]]\n",
      "[[0.48904366]]\n",
      "[[0.48879581]]\n",
      "[[0.48854801]]\n",
      "[[0.48830027]]\n",
      "[[0.48805259]]\n",
      "[[0.48780497]]\n",
      "[[0.48755741]]\n",
      "[[0.4873099]]\n",
      "[[0.48706245]]\n",
      "[[0.48681507]]\n",
      "[[0.48656774]]\n",
      "[[0.48632047]]\n",
      "[[0.48607326]]\n",
      "[[0.48582611]]\n",
      "[[0.48557901]]\n",
      "[[0.48533198]]\n",
      "[[0.485085]]\n",
      "[[0.48483809]]\n",
      "[[0.48459123]]\n",
      "[[0.48434444]]\n",
      "[[0.4840977]]\n",
      "[[0.48385102]]\n",
      "[[0.4836044]]\n",
      "[[0.48335784]]\n",
      "[[0.48311134]]\n",
      "[[0.4828649]]\n",
      "[[0.48261852]]\n",
      "[[0.4823722]]\n",
      "[[0.48212594]]\n",
      "[[0.48187974]]\n",
      "[[0.48163359]]\n",
      "[[0.48138751]]\n",
      "[[0.48114149]]\n",
      "[[0.48089552]]\n",
      "[[0.48064962]]\n",
      "[[0.48040377]]\n",
      "[[0.48015799]]\n",
      "[[0.47991226]]\n",
      "[[0.47966659]]\n",
      "[[0.47942098]]\n",
      "[[0.47917544]]\n",
      "[[0.47892995]]\n",
      "[[0.47868452]]\n",
      "[[0.47843915]]\n",
      "[[0.47819384]]\n",
      "[[0.47794859]]\n",
      "[[0.4777034]]\n",
      "[[0.47745827]]\n",
      "[[0.4772132]]\n",
      "[[0.47696818]]\n",
      "[[0.47672323]]\n",
      "[[0.47647834]]\n",
      "[[0.4762335]]\n",
      "[[0.47598873]]\n",
      "[[0.47574401]]\n",
      "[[0.47549936]]\n",
      "[[0.47525476]]\n",
      "[[0.47501022]]\n",
      "[[0.47476575]]\n",
      "[[0.47452133]]\n",
      "[[0.47427697]]\n",
      "[[0.47403267]]\n",
      "[[0.47378843]]\n",
      "[[0.47354425]]\n",
      "[[0.47330013]]\n",
      "[[0.47305607]]\n",
      "[[0.47281206]]\n",
      "[[0.47256812]]\n",
      "[[0.47232423]]\n",
      "[[0.47208041]]\n",
      "[[0.47183664]]\n",
      "[[0.47159294]]\n",
      "[[0.47134929]]\n",
      "[[0.4711057]]\n",
      "[[0.47086217]]\n",
      "[[0.47061871]]\n",
      "[[0.4703753]]\n",
      "[[0.47013194]]\n",
      "[[0.46988865]]\n",
      "[[0.46964542]]\n",
      "[[0.46940225]]\n",
      "[[0.46915913]]\n",
      "[[0.46891608]]\n",
      "[[0.46867308]]\n",
      "[[0.46843014]]\n",
      "[[0.46818727]]\n",
      "[[0.46794445]]\n",
      "[[0.46770169]]\n",
      "[[0.46745899]]\n",
      "[[0.46721635]]\n",
      "[[0.46697376]]\n",
      "[[0.46673124]]\n",
      "[[0.46648878]]\n",
      "[[0.46624637]]\n",
      "[[0.46600402]]\n",
      "[[0.46576174]]\n"
     ]
    }
   ],
   "source": [
    "from sequential import Sequential\n",
    "\n",
    "from model.layers.conv2d import Conv2D\n",
    "from model.layers.output import Output\n",
    "from model.layers.flatten import Flatten\n",
    "from model.layers.dense import Dense\n",
    "from model.layers.maxpool2d import MaxPool2D\n",
    "from model.layers.dropout import ConvDropout, DenseDropout\n",
    "import numpy as np\n",
    "\n",
    "path = '/Users/jiafeng/Library/CloudStorage/OneDrive-/cs431/final_cnn/sub_data'  #absolute path \n",
    "sequential = Sequential()\n",
    "train_value,train_target, validation_value , validation_target =sequential.preprocess_dataset(path,'c')\n",
    "\n",
    "input = train_value[0]   #np.random.uniform(low=-1, high=1, size=(2,12,12))\n",
    "\n",
    "\n",
    "# make convolutional layers\n",
    "convLayer1 = Conv2D(input_shape=(2,12,12), output_shape=(4,10,10), filters=4, kernel_size=3, activation='relu')\n",
    "convDropoutLayer = ConvDropout(input_shape=(4,10,10), output_shape=(4,10,10), dropout_rate=0.5)\n",
    "convLayer2 = Conv2D(input_shape=(4,10,10), output_shape=(10,7,7), filters=10, kernel_size=4, activation='relu')\n",
    "poolingLayer = MaxPool2D(input_shape=(10,7,7), output_shape=(10,3,3), pool_size=(5,5))\n",
    "convLayer3 = Conv2D(input_shape=(10,3,3), output_shape=(1,3,3), filters=1, kernel_size=1, activation='relu')\n",
    "\n",
    "# make flatten layer\n",
    "flattenLayer = Flatten(input_shape=(1,3,3), output_shape=(9,1), activation='relu')\n",
    "layer2 = Dense(input_shape=(9,1), output_shape=(5,1), activation='relu')\n",
    "denseDropoutLayer = DenseDropout(input_shape=(5,1), output_shape=(5,1), dropout_rate=0.5)\n",
    "layer3 = Dense(input_shape=(5,1), output_shape=(1,1), activation='relu')\n",
    "# make output\n",
    "output = Output((1,1), (1,1), train_target[0], 'sigmoid', '')\n",
    "input = np.random.uniform(low=-1, high=1, size=(2,12,12))\n",
    "sequential = Sequential()\n",
    "\n",
    "\n",
    "sequential.add(convLayer1)\n",
    "sequential.add(convLayer2)\n",
    "sequential.add(poolingLayer)\n",
    "sequential.add(convLayer3)\n",
    "sequential.add(flattenLayer)\n",
    "sequential.add(layer2)\n",
    "sequential.add(layer3)\n",
    "sequential.add(output)\n",
    "\n",
    "sequential.compile('adam')\n",
    "\n",
    "\n",
    "for i in range(150):\n",
    "    final_out =sequential.forward(input)\n",
    "    print(final_out)\n",
    "    sequential.backward(final_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Weight channel count doesn't match Input channel count. Weight shape: (3, 3, 3)  Input shape: (100, 100, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m\n\u001b[1;32m     42\u001b[0m sequential\u001b[38;5;241m.\u001b[39madd(output)\n\u001b[1;32m     44\u001b[0m sequential\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m \u001b[43msequential\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_value\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_target\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/final_cnn/group_2/CNN-Project/sequential.py:69\u001b[0m, in \u001b[0;36mSequential.training\u001b[0;34m(self, train_value, train_target, number_of_iteration)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#change the final output\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39mtarget\n\u001b[0;32m---> 69\u001b[0m output \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(output\u001b[38;5;241m=\u001b[39moutput)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/final_cnn/group_2/CNN-Project/sequential.py:23\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input, index)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m---> 23\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(output, index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/final_cnn/group_2/CNN-Project/model/layers/conv2d.py:34\u001b[0m, in \u001b[0;36mConv2D.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# convolve each kernel with result of the activation function and the input\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,kern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernels):\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput[i] \u001b[38;5;241m=\u001b[39m \u001b[43mkern\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_convolve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_activ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/final_cnn/group_2/CNN-Project/kernel.py:27\u001b[0m, in \u001b[0;36mKernel.forward_convolve\u001b[0;34m(self, input_activ)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_convolve\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_activ):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mKernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_activ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-/cs431/final_cnn/group_2/CNN-Project/kernel.py:47\u001b[0m, in \u001b[0;36mKernel._convolve\u001b[0;34m(input, weights, stride)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convolve\u001b[39m(\u001b[38;5;28minput\u001b[39m, weights, stride):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m weights\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight channel count doesn\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt match Input channel count. Weight shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  Input shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m weights\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m<\u001b[39m weights\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput bigger than weight. Weight shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  Input shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Weight channel count doesn't match Input channel count. Weight shape: (3, 3, 3)  Input shape: (100, 100, 3)"
     ]
    }
   ],
   "source": [
    "from sequential import Sequential\n",
    "\n",
    "from model.layers.conv2d import Conv2D\n",
    "from model.layers.output import Output\n",
    "from model.layers.flatten import Flatten\n",
    "from model.layers.dense import Dense\n",
    "from model.layers.maxpool2d import MaxPool2D\n",
    "from model.layers.dropout import ConvDropout, DenseDropout\n",
    "import numpy as np\n",
    "\n",
    "path = '/Users/jiafeng/Library/CloudStorage/OneDrive-/cs431/final_cnn/sub_data'  #absolute path \n",
    "sequential = Sequential()\n",
    "train_value,train_target, validation_value , validation_target =sequential.preprocess_dataset(path,'c')\n",
    "\n",
    "input = train_value[0]   #np.random.uniform(low=-1, high=1, size=(2,12,12))\n",
    "\n",
    "# make convolutional layers\n",
    "convLayer1 = Conv2D(input_shape=(3,12,12), output_shape=(4,10,10), filters=4, kernel_size=3, activation='relu')\n",
    "convDropoutLayer = ConvDropout(input_shape=(4,10,10), output_shape=(4,10,10), dropout_rate=0.5)\n",
    "convLayer2 = Conv2D(input_shape=(4,10,10), output_shape=(10,7,7), filters=10, kernel_size=4, activation='relu')\n",
    "poolingLayer = MaxPool2D(input_shape=(10,7,7), output_shape=(10,3,3), pool_size=(5,5))\n",
    "convLayer3 = Conv2D(input_shape=(10,3,3), output_shape=(1,3,3), filters=1, kernel_size=1, activation='relu')\n",
    "\n",
    "# make flatten layer\n",
    "flattenLayer = Flatten(input_shape=(1,3,3), output_shape=(9,1), activation='relu')\n",
    "layer2 = Dense(input_shape=(9,1), output_shape=(5,1), activation='relu')\n",
    "denseDropoutLayer = DenseDropout(input_shape=(5,1), output_shape=(5,1), dropout_rate=0.5)\n",
    "layer3 = Dense(input_shape=(5,1), output_shape=(1,1), activation='relu')\n",
    "# make output\n",
    "output = Output((1,1), (1,1), train_target[0], 'sigmoid', '')\n",
    "input = np.random.uniform(low=-1, high=1, size=(2,12,12))\n",
    "sequential = Sequential()\n",
    "\n",
    "\n",
    "sequential.add(convLayer1)\n",
    "sequential.add(convLayer2)\n",
    "sequential.add(poolingLayer)\n",
    "sequential.add(convLayer3)\n",
    "sequential.add(flattenLayer)\n",
    "sequential.add(layer2)\n",
    "sequential.add(layer3)\n",
    "sequential.add(output)\n",
    "\n",
    "sequential.compile('adam')\n",
    "\n",
    "\n",
    "sequential.training(train_value =train_value , train_target=train_target , number_of_iteration=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
