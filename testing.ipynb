{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00080376],\n",
       "       [-0.00063198]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = np.array([\n",
    "    [0.1, 0.4],\n",
    "    [0.8, 0.6]\n",
    "])\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "activation = [sig, lambda x:  x*(1-x)]\n",
    "grad_output = np.array([[-0.00265], [-0.00817]])\n",
    "output = np.array([[0.35], [0.9]])\n",
    "activation[1](output) * (w @ grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0026569],\n",
       "       [-0.0081723]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([\n",
    "    [0.3],\n",
    "    [0.9]\n",
    "])\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "activation = [sig, lambda x:  x*(1-x)]\n",
    "grad_output = np.array([[-0.0407]])\n",
    "output = np.array([[0.680], [0.664]])\n",
    "activation[1](output) * (w @ grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69028349]]\n",
      "[[0.68205434]]\n",
      "[[0.67401164]]\n",
      "[[0.66617304]]\n",
      "[[0.65855334]]\n",
      "[[0.65116451]]\n",
      "[[0.64401584]]\n",
      "[[0.63711406]]\n",
      "[[0.63046358]]\n",
      "[[0.62406667]]\n",
      "[[0.6179237]]\n",
      "[[0.61203339]]\n",
      "[[0.60639301]]\n",
      "[[0.60099861]]\n",
      "[[0.59584523]]\n",
      "[[0.59092708]]\n",
      "[[0.58623767]]\n",
      "[[0.58177006]]\n",
      "[[0.57751687]]\n",
      "[[0.57347051]]\n",
      "[[0.56962319]]\n",
      "[[0.56596707]]\n",
      "[[0.5624943]]\n",
      "[[0.55919708]]\n",
      "[[0.55606772]]\n",
      "[[0.55309866]]\n",
      "[[0.55028256]]\n",
      "[[0.54761223]]\n",
      "[[0.54508073]]\n",
      "[[0.54268134]]\n",
      "[[0.5404076]]\n",
      "[[0.53825328]]\n",
      "[[0.5362124]]\n",
      "[[0.53427923]]\n",
      "[[0.53244831]]\n",
      "[[0.53071439]]\n",
      "[[0.52907247]]\n",
      "[[0.52751781]]\n",
      "[[0.52604585]]\n",
      "[[0.52465228]]\n",
      "[[0.523333]]\n",
      "[[0.5220841]]\n",
      "[[0.52090187]]\n",
      "[[0.51978279]]\n",
      "[[0.51872352]]\n",
      "[[0.51772088]]\n",
      "[[0.51677188]]\n",
      "[[0.51587365]]\n",
      "[[0.51502349]]\n",
      "[[0.51421884]]\n",
      "[[0.51345728]]\n",
      "[[0.5127365]]\n",
      "[[0.51205432]]\n",
      "[[0.51140869]]\n",
      "[[0.51079764]]\n",
      "[[0.51021932]]\n",
      "[[0.50967199]]\n",
      "[[0.50915398]]\n",
      "[[0.50866372]]\n",
      "[[0.50819974]]\n",
      "[[0.50776061]]\n",
      "[[0.50734501]]\n",
      "[[0.50695167]]\n",
      "[[0.50657941]]\n",
      "[[0.5062271]]\n",
      "[[0.50589365]]\n",
      "[[0.50557808]]\n",
      "[[0.5052794]]\n",
      "[[0.50499673]]\n",
      "[[0.5047292]]\n",
      "[[0.504476]]\n",
      "[[0.50423636]]\n",
      "[[0.50400956]]\n",
      "[[0.5037949]]\n",
      "[[0.50359174]]\n",
      "[[0.50339946]]\n",
      "[[0.50321748]]\n",
      "[[0.50304525]]\n",
      "[[0.50288223]]\n",
      "[[0.50272795]]\n",
      "[[0.50258193]]\n",
      "[[0.50244372]]\n",
      "[[0.50231292]]\n",
      "[[0.50218912]]\n",
      "[[0.50207195]]\n",
      "[[0.50196105]]\n",
      "[[0.50185609]]\n",
      "[[0.50175675]]\n",
      "[[0.50166272]]\n",
      "[[0.50157373]]\n",
      "[[0.5014895]]\n",
      "[[0.50140979]]\n",
      "[[0.50133434]]\n",
      "[[0.50126292]]\n",
      "[[0.50119534]]\n",
      "[[0.50113136]]\n",
      "[[0.50107082]]\n",
      "[[0.50101351]]\n",
      "[[0.50095927]]\n",
      "[[0.50090793]]\n"
     ]
    }
   ],
   "source": [
    "from model.layers.dense import Dense\n",
    "from model.layers.output import Output\n",
    "from model.layers.input import Input\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "layer1 = Input((2,0), (2,0), 2, np.array([[0.1,0.4], [0.8,0.6]]))\n",
    "layer2 = Dense((2,0), (1,0), 2, np.array([[0.3], [0.9]]))\n",
    "layer3 = Output((1,0), (1,0), np.array([[0.5]]), 'sigmoid', '')\n",
    "\n",
    "input = np.array([[0.35,0.9]]).T\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "for i in range(100):\n",
    "    final_out = layer3.forward(layer2.forward(layer1.forward(input)))\n",
    "    print(final_out)\n",
    "    layer1.backward(layer2.backward(layer3.backward(final_out)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69028349]]\n",
      "[[0.68707769]]\n",
      "[[0.68387261]]\n",
      "[[0.68066925]]\n",
      "[[0.67746863]]\n",
      "[[0.67427179]]\n",
      "[[0.67107976]]\n",
      "[[0.66789361]]\n",
      "[[0.66471442]]\n",
      "[[0.66154325]]\n",
      "[[0.6583812]]\n",
      "[[0.65522936]]\n",
      "[[0.65208884]]\n",
      "[[0.64896074]]\n",
      "[[0.64584618]]\n",
      "[[0.64274627]]\n",
      "[[0.63966211]]\n",
      "[[0.63659482]]\n",
      "[[0.63354551]]\n",
      "[[0.63051527]]\n",
      "[[0.6275052]]\n",
      "[[0.62451639]]\n",
      "[[0.62154992]]\n",
      "[[0.61860686]]\n",
      "[[0.61568826]]\n",
      "[[0.61279516]]\n",
      "[[0.60992859]]\n",
      "[[0.60708957]]\n",
      "[[0.60427907]]\n",
      "[[0.60149808]]\n",
      "[[0.59874754]]\n",
      "[[0.59602838]]\n",
      "[[0.59334152]]\n",
      "[[0.59068781]]\n",
      "[[0.58806813]]\n",
      "[[0.58548329]]\n",
      "[[0.58293409]]\n",
      "[[0.58042129]]\n",
      "[[0.57794563]]\n",
      "[[0.57550781]]\n",
      "[[0.57310849]]\n",
      "[[0.57074831]]\n",
      "[[0.56842787]]\n",
      "[[0.56614771]]\n",
      "[[0.56390836]]\n",
      "[[0.56171031]]\n",
      "[[0.55955398]]\n",
      "[[0.5574398]]\n",
      "[[0.5553681]]\n",
      "[[0.55333922]]\n",
      "[[0.55135343]]\n",
      "[[0.54941097]]\n",
      "[[0.54751202]]\n",
      "[[0.54565673]]\n",
      "[[0.54384521]]\n",
      "[[0.54207752]]\n",
      "[[0.54035368]]\n",
      "[[0.53867367]]\n",
      "[[0.53703742]]\n",
      "[[0.53544482]]\n",
      "[[0.53389573]]\n",
      "[[0.53238996]]\n",
      "[[0.53092727]]\n",
      "[[0.5295074]]\n",
      "[[0.52813005]]\n",
      "[[0.52679487]]\n",
      "[[0.52550147]]\n",
      "[[0.52424946]]\n",
      "[[0.52303837]]\n",
      "[[0.52186773]]\n",
      "[[0.52073703]]\n",
      "[[0.51964572]]\n",
      "[[0.51859324]]\n",
      "[[0.51757899]]\n",
      "[[0.51660236]]\n",
      "[[0.51566269]]\n",
      "[[0.51475933]]\n",
      "[[0.51389158]]\n",
      "[[0.51305875]]\n",
      "[[0.51226011]]\n",
      "[[0.51149492]]\n",
      "[[0.51076245]]\n",
      "[[0.51006191]]\n",
      "[[0.50939255]]\n",
      "[[0.50875357]]\n",
      "[[0.5081442]]\n",
      "[[0.50756363]]\n",
      "[[0.50701108]]\n",
      "[[0.50648572]]\n",
      "[[0.50598677]]\n",
      "[[0.50551342]]\n",
      "[[0.50506487]]\n",
      "[[0.50464031]]\n",
      "[[0.50423896]]\n",
      "[[0.50386002]]\n",
      "[[0.5035027]]\n",
      "[[0.50316623]]\n",
      "[[0.50284984]]\n",
      "[[0.50255276]]\n",
      "[[0.50227425]]\n"
     ]
    }
   ],
   "source": [
    "from model.layers.dense import Dense\n",
    "from model.layers.output import Output\n",
    "from model.layers.input import Input\n",
    "from model.optimizers.adam import Adam\n",
    "import numpy as np\n",
    "\n",
    "adam = Adam()\n",
    "layer1 = Input((2,0), (2,0), 2, np.array([[0.1,0.4], [0.8,0.6]]))\n",
    "layer2 = Dense((2,0), (1,0), 2, np.array([[0.3], [0.9]]))\n",
    "layer2.compile(optimizer=adam)\n",
    "layer3 = Output((1,0), (1,0), np.array([[0.5]]), 'sigmoid', '')\n",
    "\n",
    "input = np.array([[0.35,0.9]]).T\n",
    "sig = lambda x: 1/(1+np.exp(-x))\n",
    "for i in range(100):\n",
    "    final_out = layer3.forward(layer2.forward(layer1.forward(input)))\n",
    "    print(final_out)\n",
    "    layer1.backward(layer2.backward(layer3.backward(final_out)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41861784]]\n",
      "[[0.41816977]]\n",
      "[[0.41772345]]\n",
      "[[0.41727885]]\n",
      "[[0.41683595]]\n",
      "[[0.41639471]]\n",
      "[[0.41595509]]\n",
      "[[0.41551706]]\n",
      "[[0.41508057]]\n",
      "[[0.41464557]]\n",
      "[[0.41421201]]\n",
      "[[0.41377983]]\n",
      "[[0.41334896]]\n",
      "[[0.41291935]]\n",
      "[[0.41249089]]\n",
      "[[0.41206353]]\n",
      "[[0.41163716]]\n",
      "[[0.41121169]]\n",
      "[[0.41078701]]\n",
      "[[0.41036301]]\n",
      "[[0.40993958]]\n",
      "[[0.40951658]]\n",
      "[[0.40909388]]\n",
      "[[0.40867135]]\n",
      "[[0.40824883]]\n",
      "[[0.40782617]]\n",
      "[[0.40740321]]\n",
      "[[0.40697978]]\n",
      "[[0.40655571]]\n",
      "[[0.40613082]]\n",
      "[[0.40570491]]\n",
      "[[0.40527781]]\n",
      "[[0.40484931]]\n",
      "[[0.40441922]]\n",
      "[[0.40398732]]\n",
      "[[0.40355342]]\n",
      "[[0.4031173]]\n",
      "[[0.40267875]]\n",
      "[[0.40223754]]\n",
      "[[0.40179346]]\n",
      "[[0.40134629]]\n",
      "[[0.40089581]]\n",
      "[[0.40044178]]\n",
      "[[0.39998399]]\n",
      "[[0.39952221]]\n",
      "[[0.39905621]]\n",
      "[[0.39858576]]\n",
      "[[0.39811065]]\n",
      "[[0.39763065]]\n",
      "[[0.39714552]]\n",
      "[[0.39665505]]\n",
      "[[0.39615902]]\n",
      "[[0.39565721]]\n",
      "[[0.39514939]]\n",
      "[[0.39463535]]\n",
      "[[0.39411487]]\n",
      "[[0.39358775]]\n",
      "[[0.39305375]]\n",
      "[[0.39251269]]\n",
      "[[0.39196435]]\n",
      "[[0.39140852]]\n",
      "[[0.390845]]\n",
      "[[0.39027359]]\n",
      "[[0.38969409]]\n",
      "[[0.3891063]]\n",
      "[[0.38851003]]\n",
      "[[0.38790509]]\n",
      "[[0.38729127]]\n",
      "[[0.3866684]]\n",
      "[[0.38603629]]\n",
      "[[0.38539475]]\n",
      "[[0.3847436]]\n",
      "[[0.38408265]]\n",
      "[[0.38341173]]\n",
      "[[0.38273065]]\n",
      "[[0.38203924]]\n",
      "[[0.38133732]]\n",
      "[[0.38062472]]\n",
      "[[0.37990126]]\n",
      "[[0.37916677]]\n",
      "[[0.37842108]]\n",
      "[[0.37766401]]\n",
      "[[0.37689539]]\n",
      "[[0.37611506]]\n",
      "[[0.37532284]]\n",
      "[[0.37451857]]\n",
      "[[0.37370208]]\n",
      "[[0.37287319]]\n",
      "[[0.37203174]]\n",
      "[[0.37117757]]\n",
      "[[0.37031049]]\n",
      "[[0.36943035]]\n",
      "[[0.36853698]]\n",
      "[[0.36763021]]\n",
      "[[0.36670986]]\n",
      "[[0.36577578]]\n",
      "[[0.36482779]]\n",
      "[[0.36386572]]\n",
      "[[0.3628894]]\n",
      "[[0.36189866]]\n",
      "[[0.36089333]]\n",
      "[[0.35987325]]\n",
      "[[0.35883823]]\n",
      "[[0.3577881]]\n",
      "[[0.35672271]]\n",
      "[[0.35564186]]\n",
      "[[0.35454538]]\n",
      "[[0.35343311]]\n",
      "[[0.35230487]]\n",
      "[[0.35116048]]\n",
      "[[0.34999977]]\n",
      "[[0.34882257]]\n",
      "[[0.34762869]]\n",
      "[[0.34641796]]\n",
      "[[0.34519022]]\n",
      "[[0.34394527]]\n",
      "[[0.34268295]]\n",
      "[[0.34140308]]\n",
      "[[0.34010549]]\n",
      "[[0.33879]]\n",
      "[[0.33745644]]\n",
      "[[0.33610463]]\n",
      "[[0.33473441]]\n",
      "[[0.3333456]]\n",
      "[[0.33193804]]\n",
      "[[0.33051156]]\n",
      "[[0.32906599]]\n",
      "[[0.32760116]]\n",
      "[[0.32611692]]\n",
      "[[0.32461312]]\n",
      "[[0.32308958]]\n",
      "[[0.32154617]]\n",
      "[[0.31998272]]\n",
      "[[0.3183991]]\n",
      "[[0.31679517]]\n",
      "[[0.31517078]]\n",
      "[[0.31352581]]\n",
      "[[0.31186014]]\n",
      "[[0.31017363]]\n",
      "[[0.30846618]]\n",
      "[[0.30673767]]\n",
      "[[0.30498802]]\n",
      "[[0.30321712]]\n",
      "[[0.30142489]]\n",
      "[[0.29961126]]\n",
      "[[0.29777616]]\n",
      "[[0.29591953]]\n",
      "[[0.29404133]]\n",
      "[[0.29214153]]\n",
      "[[0.29022009]]\n",
      "[[0.28827702]]\n",
      "[[0.28631231]]\n",
      "[[0.28432598]]\n",
      "[[0.28231805]]\n",
      "[[0.28028859]]\n",
      "[[0.27823764]]\n",
      "[[0.27616529]]\n",
      "[[0.27407163]]\n",
      "[[0.27195677]]\n",
      "[[0.26982086]]\n",
      "[[0.26766403]]\n",
      "[[0.26548647]]\n",
      "[[0.26328837]]\n",
      "[[0.26106994]]\n",
      "[[0.25883142]]\n",
      "[[0.25657308]]\n",
      "[[0.25429519]]\n",
      "[[0.25199806]]\n",
      "[[0.24968204]]\n",
      "[[0.24734748]]\n",
      "[[0.24499477]]\n",
      "[[0.24262432]]\n",
      "[[0.24023658]]\n",
      "[[0.23783201]]\n",
      "[[0.23541111]]\n",
      "[[0.23297441]]\n",
      "[[0.23052247]]\n",
      "[[0.22805586]]\n",
      "[[0.2255752]]\n",
      "[[0.22308114]]\n",
      "[[0.22057435]]\n",
      "[[0.21805552]]\n",
      "[[0.2155254]]\n",
      "[[0.21298474]]\n",
      "[[0.21043432]]\n",
      "[[0.20787497]]\n",
      "[[0.20530753]]\n",
      "[[0.20273286]]\n",
      "[[0.20015187]]\n",
      "[[0.19756547]]\n",
      "[[0.19497461]]\n",
      "[[0.19238025]]\n",
      "[[0.18978339]]\n",
      "[[0.18718502]]\n",
      "[[0.18458618]]\n",
      "[[0.18198791]]\n",
      "[[0.17939126]]\n",
      "[[0.17679732]]\n",
      "[[0.17420715]]\n",
      "[[0.17162185]]\n",
      "[[0.16904252]]\n",
      "[[0.16647026]]\n",
      "[[0.16390618]]\n",
      "[[0.16135137]]\n",
      "[[0.15880695]]\n",
      "[[0.15627402]]\n",
      "[[0.15375365]]\n",
      "[[0.15124694]]\n",
      "[[0.14875495]]\n",
      "[[0.14627874]]\n",
      "[[0.14381934]]\n",
      "[[0.14137778]]\n",
      "[[0.13895504]]\n",
      "[[0.13655211]]\n",
      "[[0.13416991]]\n",
      "[[0.13180938]]\n",
      "[[0.12947139]]\n",
      "[[0.12715681]]\n",
      "[[0.12486644]]\n",
      "[[0.12260107]]\n",
      "[[0.12036145]]\n",
      "[[0.11814828]]\n",
      "[[0.11596223]]\n",
      "[[0.11380391]]\n",
      "[[0.11167392]]\n",
      "[[0.1095728]]\n",
      "[[0.10750102]]\n",
      "[[0.10545906]]\n",
      "[[0.10344731]]\n",
      "[[0.10146614]]\n",
      "[[0.09951586]]\n",
      "[[0.09759675]]\n",
      "[[0.09570904]]\n",
      "[[0.09385292]]\n",
      "[[0.09202853]]\n",
      "[[0.09023597]]\n",
      "[[0.08847532]]\n",
      "[[0.08674658]]\n",
      "[[0.08504975]]\n",
      "[[0.08338478]]\n",
      "[[0.08175157]]\n",
      "[[0.08015001]]\n",
      "[[0.07857993]]\n",
      "[[0.07704116]]\n",
      "[[0.07553347]]\n",
      "[[0.07405663]]\n",
      "[[0.07261036]]\n",
      "[[0.07119437]]\n",
      "[[0.06980834]]\n",
      "[[0.06845193]]\n",
      "[[0.06712478]]\n",
      "[[0.06582651]]\n",
      "[[0.06455673]]\n",
      "[[0.06331503]]\n",
      "[[0.06210099]]\n",
      "[[0.06091417]]\n",
      "[[0.05975413]]\n",
      "[[0.05862041]]\n",
      "[[0.05751256]]\n",
      "[[0.0564301]]\n",
      "[[0.05537257]]\n",
      "[[0.05433948]]\n",
      "[[0.05333035]]\n",
      "[[0.05234471]]\n",
      "[[0.05138206]]\n",
      "[[0.05044193]]\n",
      "[[0.04952384]]\n",
      "[[0.0486273]]\n",
      "[[0.04775184]]\n",
      "[[0.04689699]]\n",
      "[[0.04606226]]\n",
      "[[0.0452472]]\n",
      "[[0.04445135]]\n",
      "[[0.04367424]]\n",
      "[[0.04291544]]\n",
      "[[0.04217449]]\n",
      "[[0.04145096]]\n",
      "[[0.04074442]]\n",
      "[[0.04005444]]\n",
      "[[0.03938062]]\n",
      "[[0.03872253]]\n",
      "[[0.03807979]]\n",
      "[[0.037452]]\n",
      "[[0.03683878]]\n",
      "[[0.03623975]]\n",
      "[[0.03565453]]\n",
      "[[0.03508278]]\n",
      "[[0.03452414]]\n",
      "[[0.03397827]]\n",
      "[[0.03344482]]\n",
      "[[0.03292348]]\n",
      "[[0.03241392]]\n",
      "[[0.03191584]]\n",
      "[[0.03142892]]\n",
      "[[0.03095288]]\n",
      "[[0.03048742]]\n",
      "[[0.03003226]]\n",
      "[[0.02958713]]\n",
      "[[0.02915177]]\n",
      "[[0.02872591]]\n",
      "[[0.0283093]]\n",
      "[[0.0279017]]\n",
      "[[0.02750287]]\n",
      "[[0.02711257]]\n",
      "[[0.02673059]]\n",
      "[[0.02635671]]\n",
      "[[0.0259907]]\n",
      "[[0.02563236]]\n",
      "[[0.0252815]]\n",
      "[[0.02493792]]\n",
      "[[0.02460142]]\n",
      "[[0.02427183]]\n",
      "[[0.02394896]]\n",
      "[[0.02363264]]\n",
      "[[0.0233227]]\n",
      "[[0.02301899]]\n",
      "[[0.02272133]]\n",
      "[[0.02242957]]\n",
      "[[0.02214357]]\n",
      "[[0.02186317]]\n",
      "[[0.02158825]]\n",
      "[[0.02131865]]\n",
      "[[0.02105424]]\n",
      "[[0.0207949]]\n",
      "[[0.02054051]]\n",
      "[[0.02029093]]\n",
      "[[0.02004604]]\n",
      "[[0.01980574]]\n",
      "[[0.01956991]]\n",
      "[[0.01933845]]\n",
      "[[0.01911124]]\n",
      "[[0.01888818]]\n",
      "[[0.01866918]]\n",
      "[[0.01845413]]\n",
      "[[0.01824295]]\n",
      "[[0.01803554]]\n",
      "[[0.01783181]]\n",
      "[[0.01763168]]\n",
      "[[0.01743506]]\n",
      "[[0.01724186]]\n",
      "[[0.01705202]]\n",
      "[[0.01686546]]\n",
      "[[0.01668209]]\n",
      "[[0.01650184]]\n",
      "[[0.01632465]]\n",
      "[[0.01615045]]\n",
      "[[0.01597916]]\n",
      "[[0.01581073]]\n",
      "[[0.01564508]]\n",
      "[[0.01548216]]\n",
      "[[0.01532192]]\n",
      "[[0.01516427]]\n",
      "[[0.01500919]]\n",
      "[[0.01485659]]\n",
      "[[0.01470644]]\n",
      "[[0.01455868]]\n",
      "[[0.01441326]]\n",
      "[[0.01427013]]\n",
      "[[0.01412924]]\n",
      "[[0.01399054]]\n",
      "[[0.01385398]]\n",
      "[[0.01371954]]\n",
      "[[0.01358714]]\n",
      "[[0.01345677]]\n",
      "[[0.01332837]]\n",
      "[[0.0132019]]\n",
      "[[0.01307733]]\n",
      "[[0.01295462]]\n",
      "[[0.01283372]]\n",
      "[[0.01271461]]\n",
      "[[0.01259724]]\n",
      "[[0.01248158]]\n",
      "[[0.01236761]]\n",
      "[[0.01225528]]\n",
      "[[0.01214456]]\n",
      "[[0.01203542]]\n",
      "[[0.01192783]]\n",
      "[[0.01182177]]\n",
      "[[0.0117172]]\n",
      "[[0.01161409]]\n",
      "[[0.01151241]]\n",
      "[[0.01141214]]\n",
      "[[0.01131326]]\n",
      "[[0.01121573]]\n",
      "[[0.01111953]]\n",
      "[[0.01102464]]\n",
      "[[0.01093103]]\n",
      "[[0.01083868]]\n",
      "[[0.01074756]]\n",
      "[[0.01065765]]\n",
      "[[0.01056894]]\n",
      "[[0.01048139]]\n",
      "[[0.01039499]]\n",
      "[[0.01030972]]\n",
      "[[0.01022556]]\n",
      "[[0.01014249]]\n",
      "[[0.01006048]]\n",
      "[[0.00997952]]\n",
      "[[0.0098996]]\n",
      "[[0.00982069]]\n",
      "[[0.00974277]]\n",
      "[[0.00966583]]\n",
      "[[0.00958986]]\n",
      "[[0.00951483]]\n",
      "[[0.00944073]]\n",
      "[[0.00936755]]\n",
      "[[0.00929526]]\n",
      "[[0.00922385]]\n",
      "[[0.00915332]]\n",
      "[[0.00908364]]\n",
      "[[0.0090148]]\n",
      "[[0.00894678]]\n",
      "[[0.00887958]]\n",
      "[[0.00881317]]\n",
      "[[0.00874756]]\n",
      "[[0.00868271]]\n",
      "[[0.00861863]]\n",
      "[[0.00855529]]\n",
      "[[0.0084927]]\n",
      "[[0.00843082]]\n",
      "[[0.00836967]]\n",
      "[[0.00830921]]\n",
      "[[0.00824944]]\n",
      "[[0.00819036]]\n",
      "[[0.00813194]]\n",
      "[[0.00807419]]\n",
      "[[0.00801708]]\n",
      "[[0.00796061]]\n",
      "[[0.00790478]]\n",
      "[[0.00784956]]\n",
      "[[0.00779495]]\n",
      "[[0.00774094]]\n",
      "[[0.00768753]]\n",
      "[[0.0076347]]\n",
      "[[0.00758244]]\n",
      "[[0.00753075]]\n",
      "[[0.00747962]]\n",
      "[[0.00742903]]\n",
      "[[0.00737899]]\n",
      "[[0.00732948]]\n",
      "[[0.00728049]]\n",
      "[[0.00723202]]\n",
      "[[0.00718407]]\n",
      "[[0.00713661]]\n",
      "[[0.00708965]]\n",
      "[[0.00704318]]\n",
      "[[0.00699719]]\n",
      "[[0.00695168]]\n",
      "[[0.00690663]]\n",
      "[[0.00686205]]\n",
      "[[0.00681792]]\n",
      "[[0.00677424]]\n",
      "[[0.006731]]\n",
      "[[0.0066882]]\n",
      "[[0.00664582]]\n",
      "[[0.00660387]]\n",
      "[[0.00656234]]\n",
      "[[0.00652123]]\n",
      "[[0.00648051]]\n",
      "[[0.00644021]]\n",
      "[[0.00640029]]\n",
      "[[0.00636077]]\n",
      "[[0.00632163]]\n",
      "[[0.00628287]]\n",
      "[[0.00624449]]\n",
      "[[0.00620648]]\n",
      "[[0.00616883]]\n",
      "[[0.00613155]]\n",
      "[[0.00609461]]\n",
      "[[0.00605803]]\n",
      "[[0.0060218]]\n",
      "[[0.00598591]]\n",
      "[[0.00595036]]\n",
      "[[0.00591514]]\n",
      "[[0.00588024]]\n",
      "[[0.00584568]]\n",
      "[[0.00581143]]\n",
      "[[0.0057775]]\n",
      "[[0.00574388]]\n",
      "[[0.00571057]]\n",
      "[[0.00567757]]\n",
      "[[0.00564486]]\n",
      "[[0.00561246]]\n",
      "[[0.00558034]]\n",
      "[[0.00554852]]\n",
      "[[0.00551698]]\n",
      "[[0.00548572]]\n",
      "[[0.00545475]]\n",
      "[[0.00542405]]\n",
      "[[0.00539362]]\n",
      "[[0.00536346]]\n",
      "[[0.00533356]]\n",
      "[[0.00530393]]\n",
      "[[0.00527456]]\n",
      "[[0.00524544]]\n",
      "[[0.00521658]]\n",
      "[[0.00518796]]\n",
      "[[0.0051596]]\n",
      "[[0.00513148]]\n",
      "[[0.00510359]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from model.layers.conv2d import Conv2D\n",
    "from model.layers.output import Output\n",
    "from model.layers.input import Input\n",
    "from model.optimizers.adam import Adam\n",
    "from model.layers.flatten import Flatten\n",
    "from model.layers.dense import Dense\n",
    "import numpy as np\n",
    "\n",
    "adam = Adam()\n",
    "input = np.array([[\n",
    "    [1,2,3,4,5],\n",
    "    [6,7,8,9,10],\n",
    "    [11,12,13,14,15],\n",
    "    [16,17,18,19,20],\n",
    "    [21,22,23,24,25]\n",
    "],\n",
    "[\n",
    "    [30, 31, 32, 33, 34],\n",
    "    [35, 36, 37, 38, 39],\n",
    "    [40, 41, 42, 43, 44],\n",
    "    [45, 46, 47, 48, 49],\n",
    "    [50, 51, 52, 53, 54]]\n",
    "])\n",
    "\n",
    "\n",
    "convLayer = Conv2D(input_shape=(2,5,5), output_shape=(2,3,3), filters=2, kernel_size=3)\n",
    "flattenLayer = Flatten(input_shape=(2,3,3), output_shape=(18,1), activation='sigmoid')\n",
    "flattenLayer.forward(convLayer.forward(input))\n",
    "\n",
    "adam1 = Adam()\n",
    "adam2 = Adam()\n",
    "layer2 = Dense(input_shape=(18,1), output_shape=(5,1))\n",
    "layer3 = Dense(input_shape=(5,1), output_shape=(1,1))\n",
    "\n",
    "layer2.compile(optimizer=adam1)\n",
    "layer3.compile(optimizer=adam2)\n",
    "output = Output((1,1), (1,1), np.array([[0.5]]), 'sigmoid', '')\n",
    "\n",
    "for i in range(500):\n",
    "     final_out = output.forward(layer3.forward(layer2.forward(flattenLayer.forward(convLayer.forward(input)))))\n",
    "     print(final_out)\n",
    "     layer2.backward(layer3.backward(output.backward(final_out)))\n",
    "\n",
    "#layer3.forward(layer2.forward(flattenLayer.forward(convLayer.forward(input))))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5,1) (3,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m      2\u001b[0m b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m]])\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m----> 3\u001b[0m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5,1) (3,1) "
     ]
    }
   ],
   "source": [
    "a = np.array([[1,1,1,1,1]]).T\n",
    "b = np.array([[2,2,2]]).T\n",
    "a * b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
